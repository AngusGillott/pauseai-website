---
title: State-of-the-art AI-capaciteiten versus mensen
description: Hoe slim zijn de nieuwste AI-modellen vergeleken met mensen?
---

Hoe slim zijn de nieuwste AI-modellen vergeleken met mensen?
Laten we eens kijken naar hoe de meest competente AI-systemen zich verhouden tot mensen in verschillende domeinen.
De onderstaande lijst wordt regelmatig bijgewerkt om de laatste ontwikkelingen weer te geven.

_Laatste update: 2024-09-16_

## Bovenmenselijk (Beter dan alle mensen)

- **Spellen**: Voor veel spellen ([Schaak, Go](https://en.wikipedia.org/wiki/AlphaGo_Zero), Starcraft, Dota, [Gran Turismo](https://www.technologyreview.com/2022/07/19/1056176/sonys-racing-ai-destroyed-its-human-competitors-by-being-nice-and-fast/) enz.) is de beste AI beter dan de beste mens.
- **Werkgeheugen**: Een gemiddelde mens kan ongeveer 7 items (zoals cijfers) tegelijk onthouden. Gemini 1.5 Pro [kan 99% van 7 miljoen woorden lezen en onthouden](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#sundar-note).
- **Leessnelheid**: Een model zoals Gemini 1.5 Pro kan een heel boek in 30 seconden lezen. Het kan een geheel nieuwe taal leren en teksten in een halve minuut vertalen.
- **Denksnelheid**: AI-modellen kunnen schrijven met snelheden die ver boven die van mensen liggen, en kunnen in enkele seconden volledige computerprogramma's schrijven.
- **Hoeveelheid kennis**: Moderne LLM's weten veel meer dan welke mens dan ook, met kennis die vrijwel elk domein bestrijkt. Er is geen mens wiens kennisbreedte in de buurt komt.
- **Opslagefficiëntie**: GPT-4 heeft ongeveer [1,7 biljoen parameters](https://the-decoder.com/gpt-4-architecture-datasets-costs-and-more-leaked/) (neuronverbindingen), terwijl mensen [ongeveer 100 tot 1000 keer het aantal synapsen](https://www.jax.org/news-and-insights/jax-blog/2018/December/600-trillion-synapses-and-alzheimers-disease) (neuronverbindingen) hebben. Echter, GPT-4 weet duizenden keren meer, en slaat meer informatie op in een kleiner aantal parameters.

## Beter dan de meeste mensen

- **Taal**: De beste taalmachines kunnen vrijwel alle talen vloeiend vertalen, hebben bovenmenselijke woordenschat en kunnen in veel verschillende stijlen schrijven. In december 2023 won een door AI geschreven roman een prijs op een [nationale sciencefictionwedstrijd](https://www.scmp.com/news/china/science/article/3245725/chinese-professor-used-ai-write-science-fiction-novel-then-it-won-national-award?campaign=3245725&module=perpetual_scroll_0&pgtype=article). De professor die de AI gebruikte, heeft het verhaal gemaakt vanuit een concept van 43.000 tekens die in slechts drie uur met 66 prompts zijn gegenereerd.
- **Redeneren**: o1 [beantwoordt 78%](https://openai.com/index/learning-to-reason-with-llms/) van de GPQA-diamantvragen correct, en overtreft menselijke domeinexperts (PhD's) die slechts 69,7% correct hebben.
- **Creativiteit**: Beter dan 99% van de mensen op de [Torrance Tests of Creative Thinking](https://neurosciencenews.com/ai-creativity-23585/) waar relevante en nuttige ideeën moeten worden gegenereerd. De tests waren echter relatief klein en voor grotere projecten (bijv. het opzetten van een nieuw bedrijf) is AI nog niet autonoom genoeg.
- **Overtuigingskracht**: GPT-4 met toegang tot persoonlijke informatie kon de overeenstemming van deelnemers met de argumenten van hun tegenstanders met een opmerkelijke [81,7 procent](https://arxiv.org/abs/2403.14380) verhogen vergeleken met debatten tussen mensen - bijna twee keer zo overtuigend als de menselijke debaters.
- **IQ**: Met verbale IQ-tests presteren LLM's al een tijdje beter dan 95 tot 99% van de mensen (score tussen [125](https://medium.com/@soltrinox/the-i-q-of-gpt4-is-124-approx-2a29b7e5821e) en [155](https://www.scientificamerican.com/article/i-gave-chatgpt-an-iq-test-heres-what-i-discovered/)). Met non-verbale (patroonherkenning) IQ-tests scoorde het 2024 o1-preview model [120 op de mensatest](https://www.maximumtruth.org/p/massive-breakthrough-in-ai-intelligence), en overtrof 91% van de mensen.
- **Gespecialiseerde kennis**: GPT-4 scoort 75% in het [Medical Knowledge Self-Assessment Program](https://openai.com/research/gpt-4), mensen gemiddeld tussen [65 en 75%](https://pubmed.ncbi.nlm.nih.gov/420438/). Het scoort beter dan [68](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4441311) tot [90%](https://law.stanford.edu/2023/04/19/gpt-4-passes-the-bar-exam-what-that-means-for-artificial-intelligence-tools-in-the-legal-industry/) van rechtenstudenten op het bar-examen.
- **Kunst**: Beeldgeneratiemodellen hebben [kunst](https://dataconomy.com/2022/09/26/ai-artwork-wins-art-competition) en zelfs [fotografie wedstrijden](https://www.artnews.com/art-news/news/ai-generated-image-world-photography-organization-contest-artist-declines-award-1234664549) gewonnen.
- **Onderzoek**: GPT-4 kan [autonoom chemisch onderzoek doen](https://www.nature.com/articles/s41586-023-06792-0) en DeepMind heeft een AI gebouwd die [een oplossing heeft gevonden voor een open wiskundig probleem](https://www.nature.com/articles/s41586-023-06924-6). Deze architecturen vereisen echter veel menselijke engineering en zijn niet algemeen.
- **Programmeren**: o1 verslaat [93% van de menselijke programmeurs](https://medium.com/@marcelinohambali/tech-review-openai-o1-strawberry-a-new-phd-reasoning-model-783e88734d84) in de Codeforces-competitie. AI-modellen kunnen code schrijven in bijna elke programmeertaal. Devin kan [13% van de coderingsproblemen](https://twitter.com/cognition_labs/status/1767548763134964000) oplossen en kan [geld verdienen op Upwork](https://twitter.com/cognition_labs/status/1767548768734294113).
- **Hacken**: GPT-4 kan [autonoom websites hacken](https://arxiv.org/html/2402.06664v1) en [verslaat 89% van de hackers](https://arxiv.org/pdf/2402.11814.pdf) in een Capture-the-Flag-competitie. Gelukkig falen SOTA-modellen nog steeds in essentiële taken die nodig zijn voor autonome zelfreplicatie (zie hieronder).
- **Wiskunde**: o1 behoort tot de top 500 studenten in de VS in een kwalificatiewedstrijd voor de USA Math Olympiad (AIME).

## Slechter dan de meeste mensen

- **Zeggen "Ik weet het niet"**. Bijna alle grote taalmodellen hebben dit probleem van 'hallucinatie', waarbij ze informatie verzinnen in plaats van te zeggen dat ze het niet weten. Dit lijkt misschien een relatief klein tekortkoming, maar het is een zeer belangrijke. Het maakt LLM's onbetrouwbaar en beperkt hun toepasbaarheid sterk. Studies [tonen aan](https://arxiv.org/html/2403.04307v1) dat grotere modellen veel minder hallucineren dan kleinere.
- **Een overtuigende mens zijn**. GPT-4 kan [54% van de mensen overtuigen](https://arxiv.org/abs/2405.08007) dat het een mens is, maar mensen kunnen dit 67% van de tijd doen. Met andere woorden, GPT-4 slaagt nog niet consistent voor de Turing-test.
- **Behendige beweging**. Geen enkele robot kan zich bewegen zoals een mens, maar we komen dichterbij. De [Atlas-robot kan lopen, objecten gooien en salto's maken](https://www.youtube.com/watch?v=-e1_QhJ1EhQ). Google's [RT-2](https://www.deepmind.com/blog/rt-2-new-model-translates-vision-and-language-into-action) kan doelen omzetten in acties in de echte wereld, zoals "verplaats de beker naar de wijnfles". Tesla's Optimus-robot kan [kleding vouwen](https://electrek.co/2024/01/15/tesla-optimus-robot-cant-build-cars-folding-clothes/) en de biped van Figure kan [koffie zetten](https://www.youtube.com/watch?v=Q5MKo7Idsok).
- **Zelfreplicatie**. Alle levensvormen op aarde kunnen zichzelf repliceren. AI-modellen zouden zich via het internet van computer naar computer kunnen verspreiden, maar dit vereist een set vaardigheden die AI-modellen nog niet bezitten. Een [studie uit 2023](https://arxiv.org/abs/2312.11671) somt een set van 12 taken voor zelfreplicatie op, waarvan geteste modellen er 4 voltooiden. We willen niet ontdekken [wat er gebeurt](/xrisk) als een AI-model erin slaagt zichzelf over het web te verspreiden.
- **Voortdurend leren**. Huidige SOTA LLM's scheiden leren ('training') van doen ('inference'). Hoewel LLM's kunnen leren met behulp van hun _context_, kunnen ze hun gewichten niet bijwerken terwijl ze worden gebruikt. Mensen leren en doen tegelijkertijd. Er zijn echter meerdere [potentiële benaderingen hiervoor](https://arxiv.org/abs/2302.00487). Een [studie uit 2024](https://arxiv.org/html/2402.01364v2) beschreef enkele recente benaderingen voor continu leren in LLM's.
- **Plannen**. LLM's zijn [nog niet erg goed in plannen (bijv. redeneren over hoe blokken op een tafel te stapelen)](https://openreview.net/pdf?id=YXogl4uQUO). Grotere modellen presteren echter veel beter dan kleinere.

## Het eindpunt

Naarmate de tijd verstrijkt en de mogelijkheden verbeteren, verplaatsen we items van de lagere secties naar de bovenste sectie.
Wanneer enkele specifieke [gevaarlijke mogelijkheden](/dangerous-capabilities) worden bereikt, zal AI nieuwe risico's met zich meebrengen.
Op een gegeven moment zal AI elke mens in elke denkbare maatstaf overtreffen.
Wanneer we deze superintelligentie hebben gebouwd, [zijn we waarschijnlijk snel dood](/ai-takeover).
Laten we [een pauze implementeren](/proposal) om ervoor te zorgen dat we daar niet komen.
