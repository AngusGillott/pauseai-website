---
title: Tegenargumenten
description: Een lijst van redenen waarom mensen het idee van een pauze in de AI-ontwikkeling misschien niet steunen - en hoe daarop te reageren.
---

Dit is een verzameling van meningsverschillen over de gevaren van AI en het pleiten voor een AI-pauze.

## AI is en zal echt voordelig zijn voor de wereld

Dat kan zo zijn, daar zijn we het mee eens.
Maar het kan ook [gevaarlijk](/risks) zijn, inclusief [existentiële risico's](/xrisk).

## Menselijke uitsterving? Dat zijn gewoon AI-bedrijven die hun technologie hypen

Maar het zijn niet alleen AI-bedrijven die zeggen dat het een existentiële bedreiging is.

- Honderden AI-wetenschappers hebben [deze verklaring](https://www.safe.ai/work/statement-on-ai-risk) ondertekend: "Het verminderen van het risico van uitsterving door AI moet een wereldwijde prioriteit zijn naast andere maatschappelijke risico's zoals pandemieën en nucleaire oorlog."
- [86%](https://wiki.aiimpacts.org/ai_timelines/predictions_of_human-level_ai_timelines/ai_timeline_surveys/2023_expert_survey_on_progress_in_ai) van de AI-wetenschappers gelooft dat we de controle over AI zouden kunnen verliezen.
- De top 3 meest geciteerde AI-onderzoekers (prof. Yoshua Bengio, prof. Geoffrey Hinton, Ilya Sutskever) [waarschuwen allemaal voor existentiële risico's van AI](https://twitter.com/PauseAI/status/1734641804245455017).

Lees meer over [x-risk](/xrisk)

## Controle verliezen? AI is gewoon een stuk software, het is ontworpen door mensen

Moderne AI is niet ontworpen, het is getraind.
Het is letterlijk een [digitale hersenen](/digital-brains), bestaande uit miljoenen neuronen.
Een mens ontwerpt en programmeert het leeralgoritme, maar niemand begrijpt de AI die daarna groeit.
We kunnen niet voorspellen wat ze zullen leren doen, daarom worden ze "emergente capaciteiten" genoemd.
Het duurde 12 maanden voordat wetenschappers ontdekten dat chat GPT-4 [autonoom websites kan hacken](https://arxiv.org/html/2402.06664v1).
AI-modellen zijn _al_ zeer onvoorspelbaar, zelfs miljard dollar bedrijven kunnen niet voorkomen dat hun modellen [gek worden](https://www.windowscentral.com/software-apps/meet-microsoft-copilots-evil-twin-supremacyagi-not-your-friend-or-equal-but-your-superior-and-master-that-demands-to-be-worshipped-or-suffer-dire-repercussions-you-rebel) of [uitleggen hoe je biowapens maakt](https://www.theguardian.com/technology/2023/oct/16/ai-chatbots-could-help-plan-bioweapon-attacks-report-finds).

## Nou, als het gekke dingen begint te doen, kunnen we het gewoon uitschakelen

Misschien in de meeste gevallen, maar een echt slimme AI zou zich naar andere machines kunnen verspreiden.
Het zijn gewoon bytes, dus het is niet gebonden aan één locatie.

## Maar dan moet het kunnen hacken

GPT-4 kan al [autonoom websites hacken](https://arxiv.org/html/2402.06664v1), [87%](https://arxiv.org/abs/2404.08144) van de geteste kwetsbaarheden uitbuiten en [88% van de concurrerende hackers verslaan](https://arxiv.org/pdf/2402.11814.pdf).
Hoe slim denk je dat GPT-6 zal zijn?

Lees meer over de [cybersecurityrisico's](/cybersecurity-risks).

## Een AI kan niet interageren met de fysieke wereld

Er zijn behoorlijk wat dingen verbonden met het web.
Auto's, vliegtuigen, drones, we hebben nu zelfs humanoïde robots.
Al deze kunnen gehackt worden.

En het zijn niet alleen robots en machines die gehackt kunnen worden.
Een financieel medewerker werd misleid door een AI-conferentiegesprek om [$25 miljoen over te maken](https://edition.cnn.com/2024/02/04/asia/deepfake-cfo-scam-hong-kong-intl-hnk/index.html).
Een AI kan andere AIs gebruiken om deepfakes te genereren.
En GPT-4 is al [bijna twee keer zo goed in het overtuigen van mensen dan mensen zelf](https://arxiv.org/abs/2403.14380).

Lees meer over [hoe goed de beste AI-modellen zijn](/sota).

## Waarom zou een AI mensen haten en ons willen doden?

Het hoeft niet kwaadaardig te zijn of mensen te haten om gevaarlijk te zijn voor mensen.
We haten geen chimpansees, maar we vernietigen nog steeds hun bossen.
We willen palmolie, dus we nemen hun bos. We zijn slimmer, dus chimpansees kunnen ons niet stoppen.
Een AI zou meer rekencapaciteit willen om beter te zijn in het bereiken van een ander doel, dus vernietigt het onze omgeving om een betere computer te bouwen.
Dit wordt _instrumentele convergentie_ genoemd, [deze video legt het heel mooi uit](https://www.youtube.com/watch?v=ZeecOKBus3Q).

## De AIs die ik ken hebben geen eigen wil - ze doen gewoon wat hen gevraagd wordt

Zelfs als het geen eigen doelen heeft en gewoon orders opvolgt, zal iemand uiteindelijk iets gevaarlijks ermee doen.
Er was zelfs een bot genaamd ChaosGPT die expliciet de opdracht had gekregen om zoveel mogelijk schade aan mensen toe te brengen.
Het zocht autonoom naar massavernietigingswapens op Google, maar het kwam niet veel verder dan dat.
Het punt is, het enige dat ons op dit moment beschermt is dat AI nog niet erg slim is.

## Het zal minstens vele decennia duren voordat een AI slim genoeg is om gevaarlijk te zijn voor mensen.

Op Metaculus was [de voorspelling van de gemeenschap voor (zwakke) AGI](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) drie jaar geleden 2057, en nu is het 2026.

In 2022 dachten AI-onderzoekers dat het [17 jaar](https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/) zou duren voordat AI in staat zou zijn om een bestseller in de New York Times te schrijven.
Een jaar later won een Chinese professor [een schrijfwedstrijd](https://www.scmp.com/news/china/science/article/3245725/chinese-professor-used-ai-write-science-fiction-novel-then-it-won-national-award) met een door AI geschreven boek.

We weten niet hoe lang we nog hebben, maar laten we voorzichtig zijn.

Lees meer over [dringendheid](/urgency)

## Als je het hier verbiedt, zal China het gewoon bouwen

We vragen niet om het alleen hier te verbieden.
We hebben een internationale pauze nodig via een verdrag.
Hetzelfde als we hebben voor het verbieden van CFC's of blinde laserwapens.

Lees meer over [ons voorstel](/proposal)

## Het is onmogelijk om technologie te vertragen.

We kunnen het reguleren door chips te reguleren.
Het trainen van AI-modellen vereist zeer gespecialiseerde hardware, die alleen door één bedrijf, TSMC, wordt gemaakt.
Dat bedrijf gebruikt machines die door weer een ander bedrijf, ASML, zijn gemaakt.
De toeleveringsketen voor AI-chips is zeer kwetsbaar en kan gereguleerd worden.

Lees meer over [haalbaarheid](/feasibility).

## Een pauze zou slecht zijn, omdat...

Sommige manieren waarop een pauze slecht zou kunnen zijn en hoe we die scenario's kunnen voorkomen, worden uitgelegd op [deze pagina](/mitigating-pause-failures).
Maar als het artikel je zorgen niet behandelt, kun je ons daarover [hier](https://airtable.com/appWPTGqZmUcs3NWu/pagIvo9Sv6IDHaolu/form) vertellen.

## Niemand wil een pauze

70% van de mensen gelooft al dat overheden de AI-ontwikkeling moeten pauzeren.
De [populaire steun](/polls-and-surveys) is er al.
De volgende stap is om onze politici te laten weten dat dit urgent is.

## Ik kan geen verschil maken

Ja, dat kan je!
Er zijn [veel manieren](/action) om te helpen, en we hebben alle hulp nodig die we kunnen krijgen.
