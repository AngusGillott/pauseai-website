---
title: PauseAI protest @ Bletchley Park - 1 november
description: We organiseren een protest bij Bletchley Park, tijdens de AI Safety Summit
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

- [Facebook evenement](https://www.facebook.com/events/347499967619516/347499967619516)
- [Aanmelden](https://www.mixily.com/event/4419031774197158693)

![AI-Safety-Summit-Logo](https://github.com/joepio/pauseai/assets/47218308/4b8fe05f-3f8f-4f71-87a6-d273d67ae599)

Het VK is in beweging. Het erkent vrijwel elk risico van AI, investeert ¬£100M in AI-veiligheid, organiseert een top en kondigt een AI Safety Institute aan.

Maar goed is niet goed genoeg. Top AI-experts zoals Geoffrey Hinton en Yoshua Bengio hebben heel duidelijk gemaakt: we weten niet hoe we een supermenselijke AI kunnen beheersen. Als we dit verkeerd doen, is menselijke uitsterving een zeer re√´le mogelijkheid. Daarom roepen we op tot een onmiddellijke en onbepaalde pauze op grensverleggend AI-onderzoek en -ontwikkeling.

Op 1 en 2 november zal de allereerste AI Safety Summit plaatsvinden in het VK.
Dit is een gouden kans om de eerste stappen te zetten richting verstandige internationale AI-veiligheidsregulering.

Echter, het lijkt erop dat de verantwoordelijken [niet voelen hoe weinig tijd we misschien hebben](/urgency).
De organisator en de vertegenwoordiger van de premier voor de AI Safety Summit, Matt Clifford, heeft [verklaard](https://twitter.com/PauseAI/status/1709845853668553065) dat ‚Äúhet nu pauzeren van AI-ontwikkeling prematuur zou zijn‚Äù, en dat hij [geen ‚Äúharde controles‚Äù verwacht](https://twitter.com/matthewclifford/status/1708819574739587356) van de top.
Het AI-veiligheidsdocument dat vorige week is vrijgegeven [suggereert](https://twitter.com/PauseAI/status/1717474950557090151) dat het VK er vertrouwen in heeft dat we nog vele jaren de tijd hebben om ons voor te bereiden op AGI.
Maar het VK vertrouwt op schattingen van vorig jaar, voordat ChatGPT werd uitgebracht.
Op Metaculus is de voorspelling van de datum van de eerste AGI [gedaald](https://metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) van 2047 naar 2026 in de afgelopen 18 maanden!

**We hebben onze leiders nodig om aan de veilige kant te blijven en NU een pauze in te voeren.**

## Wat we vragen

- **Beleidsmakers**: Sta bedrijven niet toe om een superintelligentie te bouwen. Reguleringen en hardwarebeperkingen moeten van toepassing zijn voordat de training is begonnen, omdat het zeer moeilijk is om verspreiding te beheersen zodra een nieuwe mogelijkheid is bereikt. We kunnen niet toestaan dat bedrijven potentieel wereldvernietigende AI-modellen trainen. Wetgeving schrijven is moeilijk en kost tijd, maar we hebben misschien niet zo lang, dus werk alsof je leven ervan afhangt. Omdat dat zo is.
- **Bedrijven**: Velen van jullie zijn bang voor wat AI kan doen, maar jullie zitten vast in een race. Wees daarom openhartig over het ondersteunen van een pauze in principe. Als je verklaringen ondertekent dat deze technologie ons allemaal zou kunnen doden, laat de wereld dan zien dat je het liever niet zou bouwen als dat een haalbare optie was.
- **Genodigden van de top**: Geef prioriteit aan veiligheid boven economische groei. We weten dat AI onze landen rijker kan maken, maar dat is niet waarom je hier bent opgeroepen. Wees de volwassene in de kamer.

Voor ons volledige voorstel, zie [hier](/proposal).

## Persbericht

_VOOR PUBLICATIE OP 1 NOVEMBER 2023_

### Protest Tijdens AI Safety Summit Roept Op Tot Stopzetting van Gevaarlijke AI-ontwikkeling

**1 november:** [**PauseAI**](https://pauseai.info/) **houdt een** [**protest in Bletchley Park, tijdens de AI Safety Summit**](https://pauseai.info/2023-oct) **en roept beleidsmakers en deelnemers van de AI Safety Summit op om onmiddellijk de creatie van een superintelligente AI te verbieden.**

In maart dit jaar hebben veel opmerkelijke figuren [een brief](https://futureoflife.org/open-letter/pause-giant-ai-experiments/#:~:text=We%20call%20on%20all%20AI,more%20powerful%20than%20GPT%2D4.&text=AI%20systems%20with%20human%2Dcompetitive,acknowledged%20by%20top%20AI%20labs.) ondertekend waarin wordt opgeroepen tot een pauze van zes maanden op de ontwikkeling van hun grensverleggende AI-modellen. In mei ondertekenden honderden AI-wetenschappers [een verklaring](https://www.safe.ai/statement-on-ai-risk) waarin staat: ‚ÄúHet mitigeren van het risico op uitsterving door AI moet een wereldwijde prioriteit zijn naast andere maatschappelijke risico's zoals pandemie√´n en nucleaire oorlog.‚Äù

Recente peilingen in [de VS](https://www.vox.com/future-perfect/2023/9/19/23879648/americans-artificial-general-intelligence-ai-policy-poll) en [het VK](https://inews.co.uk/news/politics/voters-deepfakes-ban-ai-intelligent-humans-2708693) hebben aangetoond dat een grote meerderheid van de mensen wil dat de overheid ingrijpt en voorkomt dat een superintelligente AI wordt gebouwd. Tot nu toe zijn er [geen ontwerpwetten](https://twitter.com/PauseAI/status/1706605169608159458) voorgesteld die dit zouden doen.

Op 1 en 2 november vindt de allereerste AI Safety Summit plaats in Bletchley Park, VK.
De top wordt bijgewoond door vooraanstaande AI-wetenschappers, beleidsmakers en bedrijfsleiders.
Dit markeert een unieke kans om de eerste stappen te zetten richting internationale AI-veiligheidsregulering.
Echter, het VK is niet van plan deze kans te gebruiken om sterke AI-regulering in te voeren.
De organisator en de vertegenwoordiger van de premier voor de AI Safety Summit, Matt Clifford, heeft [verklaard](https://twitter.com/PauseAI/status/1709845853668553065) dat ‚Äúhet nu pauzeren van AI-ontwikkeling prematuur zou zijn‚Äù, en dat hij [geen ‚Äúharde controles‚Äù verwacht](https://twitter.com/matthewclifford/status/1708819574739587356) van de top.

‚ÄúWe zijn blij dat het VK de leiding neemt in AI-veiligheid en internationale leiderschap toont‚Äù, zegt Joep Meindertsma, directeur van PauseAI. ‚ÄúMaar we zien niet het niveau van urgentie dat het verdient. In 2020 [voorspelden](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) voorspellers de komst van AI op menselijk niveau in 2055. Vandaag is de [gemiddelde voorspelling](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) 2026. We kunnen geen ramp riskeren door de snelheid van de vooruitgang te onderschatten. We hebben onze politici nodig om aan de veilige kant te blijven. Elk leven is in gevaar. Geen enkel bedrijf mag een superintelligentie bouwen.‚Äù

### Media

[Het protest werd behandeld in NewScientist.](https://www.newscientist.com/article/2400626-uk-ai-summit-is-a-photo-opportunity-not-an-open-debate-critics-say/)

<WidgetConsent>
<div><blockquote class="twitter-tweet"><p lang="en" dir="ltr">We protesteerden tijdens de AI Safety Summit in Bletchley Park om te eisen dat onze leiders de ontwikkeling van superintelligente AI stopzetten. <br><br>üßµ <a href="https://t.co/WbH1GuKqAS">pic.twitter.com/WbH1GuKqAS</a></p>&mdash; PauseAI ‚è∏ (@PauseAI) <a href="https://twitter.com/PauseAI/status/1719740149905400128?ref_src=twsrc%5Etfw">1 november 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div>
</WidgetConsent>
