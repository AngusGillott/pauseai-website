---
title: PauseAI / Geen AGI Protest @ OpenAI San Francisco - 12 februari 2024
description: We organiseren een protest om een pauze te eisen op gevaarlijke AI-ontwikkeling.
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

- PauseAI protest
- Waar: San Francisco, OpenAI HQ
- Wanneer: 12 februari 2024, 16:30 - 18:00
- [Facebook evenement](https://fb.me/e/78BzWmaaj)
- [Website](https://openaiprotest.com/)

Andere internationale locaties / tijden:
VK (exacte locatie TBD) / 16:00 GMT

## Waarom we protesteren tegen OpenAI

OpenAI probeert een AI te bouwen die slimmer is dan mensen.
Honderden wetenschappers waarschuwen dat dit het einde van de mensheid kan veroorzaken.
Dit is de reden waarom meer dan 33.000 mensen de Pauze-brief hebben ondertekend, waarin AI-bedrijven zoals OpenAI worden aangespoord om hun vooruitgang te stoppen.
Zelfs Sam Altman, de CEO van OpenAI, heeft gezegd dat we op de rem moeten trappen ["als AI-modellen verbeteren op manieren die we niet volledig begrijpen"](https://time.com/6288584/openai-sam-altman-full-interview/).
In een ander interview noemde Sam het voorspellen van mogelijkheden een ["leuk gokspel"](https://www.ft.com/content/dd9ba2f6-f509-42f0-8e97-4271c7b84ded) voor OpenAI-medewerkers.
Met andere woorden: zelfs OpenAI begrijpt niet hoe hun modellen verbeteren.
De tijd om op de rem te trappen is _nu_.

## Sluit je bij ons aan en zeg tegen OpenAI "Stop met werken met het Pentagon!"

Op 10 januari, zonder enige aankondiging, verwijderde OpenAI de taal in zijn gebruiksbeleid\* die stelde dat OpenAI niet toestaat dat zijn modellen worden gebruikt voor "activiteiten die een grote kans op schade met zich meebrengen", zoals "militaire en oorlogsvoering". Vervolgens meldde TIME op 17 januari dat OpenAI het Pentagon als klant zou aannemen. Op 12 februari zullen we eisen dat OpenAI zijn relatie met het Pentagon beëindigt en geen militaire klanten aanneemt. Als hun ethische en veiligheidsgrenzen uit gemak kunnen worden herzien, kunnen ze niet worden vertrouwd.

AI wordt snel krachtiger, veel sneller dan vrijwel elke AI-wetenschapper had voorspeld. Er worden miljarden geïnvesteerd in AI-capaciteiten, en de resultaten zijn verbluffend. Nieuwe modellen presteren beter dan mensen in veel domeinen. Naarmate de mogelijkheden toenemen, nemen ook de risico's toe. Wetenschappers waarschuwen zelfs dat AI de mensheid zou kunnen vernietigen.

Volgens hun handvest is "de missie van OpenAI ervoor te zorgen dat kunstmatige algemene intelligentie (AGI)—waarmee we zeer autonome systemen bedoelen die mensen overtreffen in al het economisch waardevolle werk—ten goede komt aan de hele mensheid." Maar veel mensen waarderen hun werk en vinden er betekenis in, en willen daarom niet dat hun banen door een AGI worden overgenomen. Wat protestco-organisator Sam Kirchner van No AGI "de Psychologische Bedreiging" noemt, geldt zelfs als AGI ons niet doodt.

## Contact

- Holly Elmore ([Twitter](https://twitter.com/ilex_ulmus))
- Sam Kirchner ([Twitter](https://twitter.com/No_AGI_))

## Media-aandacht

- [Bloomberg](https://www.bloomberg.com/news/newsletters/2024-02-13/ai-protest-at-openai-hq-in-san-francisco-focuses-on-military-work)
- [ReadWrite](https://readwrite.com/stop-working-with-pentagon-openai-staff-face-protests/)
- [VentureBeat](https://venturebeat.com/ai/protesters-gather-outside-openai-office-opposing-military-ai-and-agi/)

<WidgetConsent>
<div>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">From the protest yesterday at OpenAI HQ, covered in Bloomberg: <a href="https://t.co/sgp1KFoFPs">https://t.co/sgp1KFoFPs</a> <a href="https://t.co/N6fHGIlOYm">pic.twitter.com/N6fHGIlOYm</a></p>&mdash; PauseAI US ⏸️ (@pauseaius) <a href="https://twitter.com/pauseaius/status/1757604719047114786?ref_src=twsrc%5Etfw">February 14, 2024</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</WidgetConsent>
