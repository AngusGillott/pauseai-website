---
title: PauseAI protest @ Parliament Square - 8 juni
description: We organiseren een protest op Parliament Square om een top te eisen om de ontwikkeling van AI te pauzeren.
---

- PauseAI protest, waarin Rishi Sunak wordt aangespoord om een pauze op de ontwikkeling van AI in te voeren.
- Waar: Parliament Square, Londen
- Wanneer: 8 juni, 16:00 - 18:00

## Persbericht

Op donderdag 8 juni zullen vrijwilligers van de nieuwe [PauseAI](http://pauseai.info) beweging zich verzamelen op Parliament Square, Londen, om de Britse regering aan te sporen het voortouw te nemen in het pauzeren van de ontwikkeling van krachtigere en gevaarlijkere AI-systemen.

Een snel toenemend aantal AI-experts heeft vorige week een verklaring [ondertekend](https://www.safe.ai/statement-on-ai-risk) die luidt:

> "Het mitigeren van het risico op uitsterven door AI zou een mondiale prioriteit moeten zijn, naast andere risico's op maatschappelijk niveau zoals pandemieën en nucleaire oorlog."

Deze verklaring is ondertekend door vrijwel alle AI-laboratoria (OpenAI, Google DeepMind, Anthropic) en honderden AI-wetenschappers, waaronder Geoffrey Hinton, de "Godfather of AI".

AI-veiligheidsonderzoekers hebben geen consensus bereikt over hoe groot het risico op menselijke uitsterving zal zijn.
Resultaten van de ["Existential risk from AI survey"](https://forum.effectivealtruism.org/posts/8CM9vZ2nnQsWJNsHx/existential-risk-from-ai-survey-results) tonen aan dat de schattingen variëren van 2% tot 98%, met een gemiddelde van 30%.

Rishi Sunak heeft verklaard dat de ["regering hier zeer zorgvuldig naar kijkt"](https://twitter.com/RishiSunak/status/1663838958558539776) en dat ["het VK goed geplaatst is om leiding te geven"](https://twitter.com/RishiSunak/status/1662369922234679297) aan de wereldwijde samenwerking op het gebied van veilige AI-ontwikkeling.
Het VK herbergt enkele van de toonaangevende AI-laboratoria ter wereld, waaronder Google DeepMind, en heeft een hoge concentratie van AI-veiligheidsonderzoekers.
Gisteren, op 7 juni, heeft de Britse regering [aangekondigd](https://www.gov.uk/government/news/uk-to-host-first-global-summit-on-artificial-intelligence) dat het deze herfst de eerste wereldwijde AI-top zal organiseren.

De demonstranten dringen er bij Rishi Sunak op aan om het voortouw te nemen in de wereldwijde AI-veiligheid en de ontwikkeling van gevaarlijkere AI-systemen te pauzeren, terwijl hij de weg leidt naar democratische controle over de ontwikkeling van AI.
Ze vragen hem om prioriteit te geven aan de pauze op de [top](https://pauseai.info/summit).
Het pauzeren van de AI-ontwikkeling is een andere benadering dan wat de CEO's van AI-laboratoria met wie Rishi Sunak heeft gesproken, hebben voorgesteld.
OpenAI gelooft dat ["het onintuitief riskant en moeilijk zou zijn om de creatie van superintelligentie te stoppen"](https://openai.com/blog/governance-of-superintelligence), dus zij streven verdere ontwikkeling naar superintelligentie na.

> "We hebben een keuze: riskeren we alles om een superintelligentie te bouwen waar het publiek nooit over is geraadpleegd, of stoppen we terwijl we nog kunnen?" - PauseAI demonstranten

> "AI-bedrijven brengen alles in gevaar; we zien al de schade, en het zal veel erger worden. Technologieontwikkeling is niet onvermijdelijk, en pauzeren moet als een haalbare optie worden beschouwd. We kunnen de toekomst niet overlaten aan een paar CEO's die erkennen dat ze bereid zijn de mensheid te riskeren voor hun dromen. We verdienen allemaal een stem in onze toekomst, en een wereldwijde pauze geeft ons die kans."

> "Ondanks het erkennen van de gevaren van voortdurende AI-ontwikkeling, gebruiken deze bedrijven het slechts als een excuus om door te gaan, en lijken ze te weigeren deze gevaarlijke macht vrijwillig op te geven. In dergelijke situaties is wereldwijde samenwerking om deze gevaarlijke ontwikkeling in te tomen essentieel, zodat we ervoor zorgen dat technologieontwikkeling voor iedereen werkt. Het VK is goed geplaatst om hierin het voortouw te nemen door een wereldwijde top te organiseren om AI te pauzeren en de AI-ontwikkeling onder democratische controle te brengen."

> "We hebben misschien niet de luxe van tijd. AI-ontwikkelingen gebeuren in een razend tempo, en we moeten nu handelen om de ergste scenario's te voorkomen. De top in de herfst zou zelfs te laat kunnen zijn om het ergste te voorkomen. We dringen er bij Rishi Sunak op aan om de AI-ontwikkelingen te stoppen vóór de top. Zelfs als alleen het VK en de VS overeenkomen om te pauzeren tot de top, hebben we een enorme stap gezet richting het voorkomen van de ergste scenario's."

De PauseAI-demonstranten hebben concrete [agendasuggesties](/summit) en [beleidsvoorstellen](/proposal) voor de top.

Voor meer informatie, bezoek [PauseAI.info](http://pauseai.info).

## Contact

- Gideon Futerman ([Twitter](https://twitter.com/GFuterman))
