---
title: Communicatiestrategie
description: Hoe we communiceren over het pauzeren van AI-ontwikkeling.
---

## Hoe we communiceren

- **Vertrouw op experts**. We waarschuwen mensen voor een scenario dat zo extreem en beangstigend is, dat een instinctieve reactie is om het als onzin af te doen. Toon de [expertpeilingen en enquêtes](/polls-and-surveys). De [top drie](https://twitter.com/PauseAI/status/1734641804245455017) meest geciteerde AI-wetenschappers waarschuwen allemaal voor x-risico. Vertrouwen op hen is een goede manier om onze zaak te onderbouwen.
- **Gebruik eenvoudige taal**. Je kunt laten zien dat je de technologie begrijpt en je huiswerk hebt gedaan, maar overmatig jargon kan mensen de interesse doen verliezen. We willen zoveel mogelijk mensen bereiken, dus maak de taal niet te ingewikkeld. Veel van de mensen die we willen bereiken zijn niet-native Engelse sprekers, dus overweeg om vertalingen te maken.
- **Toon onze emoties**. Emoties zien geeft anderen de toestemming om emoties te voelen. We zijn bezorgd, we zijn boos, we zijn gretig om te handelen. Tonen hoe je je voelt kan eng zijn, maar in ons geval moeten we dat doen. Onze boodschap kan alleen worden ontvangen als deze overeenkomt met hoe we deze verzenden.
- **Benadruk onzekerheid**. Zeg niet dat AI _zal_ overnemen, of dat we _binnen_ x jaren AGI _zullen_ bereiken. Niemand kan de toekomst voorspellen. Er is een aanzienlijke _kans_ dat AI binnenkort verkeerd zal gaan, en dat zou genoeg moeten zijn om actie te ondernemen. Laat onzekerheid niet de reden zijn om niet te handelen. Verwijs naar het _Voorzorgsprincipe_ en maak het punt dat we aan de veilige kant moeten blijven.
- **Laat individuen zich verantwoordelijk voelen**. Niemand wil het gevoel hebben dat ze een sterke verantwoordelijkheid hebben om dingen goed te laten verlopen. Onze hersenen sturen ons hier vanaf, omdat we allemaal een diep verlangen hebben om te geloven dat iemand de leiding heeft en ons beschermt. Maar er zijn op dit moment geen volwassenen in de kamer. Jij moet degene zijn die dit doet. Kies ervoor om verantwoordelijkheid te nemen.
- **Inspireer hoop**. Wanneer we horen over de gevaren van AI en de huidige race naar beneden, zullen velen van ons een gevoel van vrees ervaren, en dat maakt dat we niet handelen. Fatalisme is comfortabel, omdat een gebrek aan hoop betekent dat we niet hoeven te werken aan een goed resultaat. Daarom moeten we benadrukken dat onze zaak niet verloren is. AGI is [niet onvermijdelijk](/feasibility), technologie is internationaal succesvol verboden, en ons voorstel heeft brede publieke steun.

## No-gos

- **Geen AI-gegenereerde inhoud**. Het gebruik van AI-modellen is prima voor onderzoek, ideevorming en het itereren op ideeën, maar publiceer geen AI-gegenereerde inhoud alsof het van ons is - vooral geen AI-gegenereerde afbeeldingen of video's. Zelfs als we niet anti-AI zijn, kunnen we gemakkelijk als hypocrieten worden bestempeld als we duidelijk AI-gegenereerde inhoud gebruiken.
- **Geen partijdige politiek**. We steunen geen enkele politieke partij of ideologie. We hebben geen meningen over zaken buiten AI.
- **Geen tactische zelfcensuur**. Sommige AI Governance-organisaties kiezen ervoor niet te zeggen hoe bezorgd ze zijn, of kiezen ervoor niet te pleiten voor de beleidsmaatregelen die ze noodzakelijk achten _omdat ze zich zorgen maken over het verliezen van geloofwaardigheid_. We kunnen dezezelfde strategie niet kopiëren, want als we dat allemaal doen, is er niemand meer om de waarheid te spreken.
- **Geen geruchten**. We promoten geen vage of ongeverifieerde informatie. We kunnen het ons niet veroorloven om geloofwaardigheid te verliezen door valse informatie te verspreiden.

## Verhalen die we pushen

- **AI is niet alleen een hulpmiddel**. AI-modellen zijn niet geprogrammeerd, ze zijn [digitale hersenen](/digital-brains). We begrijpen niet hoe ze werken, we kunnen niet voorspellen wat ze kunnen doen, we kunnen hun gedrag niet goed controleren.
- **AI hoeft niet sentient te zijn om gevaarlijk te zijn**. In staat zijn om de wereld te ervaren of emoties te voelen is geen vereiste voor AI om gevaarlijke acties te ondernemen. Het enige dat telt zijn de [capaciteiten](/dangerous-capabilities).
- **Wereldwijde race naar beneden**. Dit is geen race die gewonnen kan worden. Het gaat niet om de VS versus China, het gaat om de mensheid versus AI. We kunnen niet verwachten superintelligente AI als wapen te gebruiken - we weten niet of het überhaupt kan worden gecontroleerd.
- **Bestaande AI-schade zal verergeren**. Deepfakes, baanverlies, surveillance, desinformatie, polarisatie... Bestaande AI veroorzaakt al schade en we moeten dat erkennen. De schade zal alleen maar erger worden met krachtigere AI, en we moeten AI pauzeren om te voorkomen dat dit gebeurt.
- **Supermenselijke AI is niet onvermijdelijk**. Het vereist horden ingenieurs met miljoen-dollar salarissen. Het vereist zeer gespecialiseerde hardware, gemaakt door een handvol monopolies. Het vereist dat we allemaal achterover leunen en niets doen.
- **Internationale regulering is mogelijk**. We hebben gezamenlijk de ozonlaag beschermd door CFC's en blinde laserwapens wereldwijd te verbieden. De gecentraliseerde AI-chipleveringsketen maakt het handhaven van computergovernance zeer [haalbaar](/feasibility).

Een groot deel van onze strategie is afgeleid van onze [waarden](https://pauseai.info/values).
