---
title: Naar de volgende AI-top (Parijs 2025)
description: Waarom we de AI-veiligheidstop nodig hebben en wat het zou moeten bereiken.
---

AI presenteert talrijke [risico's](/risks) voor de mensheid, waaronder het [risico op uitsterven](/xrisk).
De vooruitgang in AI-capaciteiten versnelt in een [frantic pace](/urgency), en we zijn niet voorbereid op de gevolgen.
AI-bedrijven zijn verwikkeld in een race naar de bodem, waar veiligheid niet de hoogste prioriteit heeft.
We hebben regeringen nodig om in te grijpen en te voorkomen dat AI supermenselijke niveaus bereikt voordat we weten hoe we het veilig kunnen maken.
Deze [pauze](/proposal) moet op internationaal niveau plaatsvinden omdat landen verwikkeld zijn in een race die vergelijkbaar is met die van de bedrijven.
**De enige manier om een echte pauze te bereiken is via een top.**

## Wat zou de volgende AI-veiligheidstop moeten bereiken?

Het doel van een top is vaak een _verdrag_, wat een formele overeenkomst is tussen twee of meer staten met betrekking tot vrede, alliantie, handel of andere internationale betrekkingen.
In ons geval hopen we op een AI-veiligheidsverdrag, dat een overeenkomst zou zijn tussen de deelnemende staten om [de AI-ontwikkeling te pauzeren](/proposal) totdat de risico's beter begrepen zijn.

## 2023 VK AI-veiligheidstop

Het primaire doel van PauseAI was om één regering te overtuigen om zo'n top te organiseren.
Slechts 5 weken na de eerste PauseAI-protest, [aankondigde](https://www.gov.uk/government/news/uk-to-host-first-global-summit-on-artificial-intelligence) de Britse regering dat zij een AI-veiligheidstop zouden organiseren, die plaatsvond op 1 en 2 november 2023.
De top was relatief klein (slechts 100 mensen waren uitgenodigd) en vond plaats in Bletchley Park.
Het leidde helaas niet tot een verdrag.
Het leidde echter wel tot de ["Bletchley Declaration"](https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023), die door alle 28 deelnemende landen werd ondertekend.
In deze verklaring erkenden de landen de AI-risico's (inclusief 'problemen van controle met betrekking tot afstemming op menselijke intentie').
Naar onze mening is deze verklaring een belangrijke eerste stap, maar het is verre van genoeg.
We hebben een daadwerkelijk bindend verdrag nodig dat de ontwikkeling van grensverleggende AI pauzeert.

Deze top leidde ook tot de aankondiging van twee vervolgtoppen voor 2024, in Seoul en Parijs.

## 2024 Zuid-Korea AI-veiligheidstop (21 en 22 mei)

Maandenlang was het onduidelijk wat de reikwijdte van deze Seoul-top zou zijn.
Alles wat we wisten, was dat het een ["virtuele mini-top"](https://www.bracknellnews.co.uk/news/national/23898764.ai-safety-institute-will-make-uk-global-hub-rishi-sunak-says/) zou worden.
Een vrij onambitieuze manier om om te gaan met de zeer alarmerende oproepen tot regulering.
In april 2024 werd de tweede AI-veiligheidstop [officieel aangekondigd](https://www.gov.uk/government/news/uk-and-republic-of-korea-to-build-on-legacy-of-bletchley-park) door de Britse regering.
We [organiseerden een protest op 13 mei](/2024-may) om onze ministers te overtuigen om de top bij te wonen (sommigen waren [niet van plan om zelfs maar aanwezig te zijn](https://www.reuters.com/technology/second-global-ai-safety-summit-faces-tough-questions-lower-turnout-2024-04-29/) en om verdragsonderhandelingen te starten voor een pauze.

De top leidde tot de volgende zaken:

1. 16 bedrijven (de meest prominente AI-bedrijven) ondertekenden de ["Frontier AI Safety Commitments"](https://www.gov.uk/government/news/historic-first-as-companies-spanning-north-america-asia-europe-and-middle-east-agree-safety-commitments-on-development-of-ai?utm_source=substack&utm_medium=email), wat betekent dat deze bedrijven RSP's zullen publiceren. Eerdere vrijwillige toezeggingen [werden genegeerd](https://www.politico.eu/article/rishi-sunak-ai-testing-tech-ai-safety-institute/).
2. Een [nieuwe verklaring](https://www.gov.uk/government/publications/seoul-ministerial-statement-for-advancing-ai-safety-innovation-and-inclusivity-ai-seoul-summit-2024/seoul-ministerial-statement-for-advancing-ai-safety-innovation-and-inclusivity-ai-seoul-summit-2024) werd ondertekend door 27 landen.

## ~~2024~~ 2025 Frankrijk AI ~~veiligheid~~ Actie-top

Frankrijk koos ervoor om een AI-veiligheidstop te organiseren in november 2024, maar heeft deze uitgesteld naar februari 2025.
Het is ook hernoemd naar "AI Actie-top", waarbij de uiterst belangrijke focus op "veiligheid" is geschrapt.
We hebben gehoord dat veiligheid slechts één van de vijf sporen op de top zal zijn.
Het wordt geleid door AI-scepticus Anne Bouverot, die [afwijzend](https://legrandcontinent-eu.translate.goog/es/2023/12/08/la-ia-no-nos-sustitira-una-conversacion-con-anne-bouverot-yann-le-cun-y-alexandre-viros/?_x_tr_sl=es&_x_tr_tl=en&_x_tr_hl=en&_x_tr_pto=sc) is over "alarmistisch discours", waarbij ze AI vergelijkt met rekenmachines en AI-veiligheidszorgen vergelijkt met Y2K-zorgen, en zeker is dat "AI ons niet gaat vervangen, maar ons eerder zal helpen".
Het lijkt steeds onwaarschijnlijker dat deze top zal leiden tot de soorten internationale reguleringen waar we voor pleiten.

## Voorbeelden van toppen en resulterende verdragen

- **Montreal Protocol** (1987): Het Montreal Protocol is een internationaal milieuverdrag dat is ontworpen om de ozonlaag te beschermen door de productie en consumptie van ozonafbrekende stoffen geleidelijk af te schaffen. Het is zeer succesvol geweest in het verminderen van het gebruik van stoffen zoals chlorofluorkoolwaterstoffen (CFK's) en heeft bijgedragen aan het geleidelijke herstel van de ozonlaag.
- **Stockholm-conventie inzake persistente organische verontreinigende stoffen** (2001): De Stockholm-conventie is een internationaal verdrag dat gericht is op het beschermen van de menselijke gezondheid en het milieu tegen persistente organische verontreinigende stoffen (POP's). Dit zijn giftige chemicaliën die in het milieu blijven bestaan, zich bioaccumuleren in levende organismen en ernstige nadelige effecten op de menselijke gezondheid en ecosystemen kunnen hebben. Wetenschappers uitten bezorgdheid over de schadelijke effecten van POP's, waaronder hun vermogen om lange afstanden te reizen via lucht- en waterstromen. De conventie leidde tot het verbieden of ernstige beperkingen op de productie en het gebruik van verschillende POP's, waaronder polychloorbifenylen (PCB's), dichloor-diphenyl-trichloorethaan (DDT) en dioxines.

## Voorgestelde educatieve agenda

Veel mensen zullen de AI-veiligheidstop bijwonen, en niet iedereen zal diep vertrouwd zijn met AI-veiligheid.
Ze moeten in staat zijn om de discussies te volgen en weloverwogen beslissingen te nemen.
Daarom geloven we dat het van groot belang is om onderwijs over x-risk een onderdeel van de top te maken.

Een bijzonder interessante (maar onconventionele) benadering is om deelnemers te verplichten om [te leren](/learn) over AI-veiligheid voordat ze de top bijwonen.
Bovendien zou de top zelf enkele dagen onderwijs over AI-veiligheid en beleid moeten omvatten.

Het volgende is een voorgestelde agenda voor de top:

- **Inleiding tot Kunstmatige Intelligentie**. Zonder de basisprincipes van AI te begrijpen, is het bijna onmogelijk om de risico's te begrijpen.
  - Neurale netwerken.
  - Grote taalmodellen.
  - Marktdynamiek van AI.
- **AI-veiligheid**. De moeilijkheid van het afstemprobleem is niet voor de hand liggend. Het begrijpen van de kernuitdagingen van het veld is noodzakelijk om de urgentie van de situatie te begrijpen.
  - Wat is een superintelligentie.
  - Het afstemprobleem.
  - Instrumentele convergentie.
  - Orthogonaliteitstheorie.
- **AI-veiligheidsbeleid**. Het besturen van het complexe veld van AI-veiligheid is niet eenvoudig. We moeten de uitdagingen en kansen van AI-veiligheidsbeleid begrijpen.
  - Internationaal niveau.
  - Financiering van AI-veiligheidsonderzoek.
  - Risico's van AI-onderzoekspublicaties.
  - Bestuur van open source-modellen.
- **Onderhandeling van het verdrag**. Zie [ons voorstel](/proposal) voor concrete suggesties over de inhoud van het verdrag.
