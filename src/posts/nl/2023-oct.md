---
title: Internationale PauseAI-protest 21 oktober 2023
description: We organiseren een internationale protest om een pauze te eisen op gevaarlijke AI-ontwikkeling.
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

## 21 oktober (zaterdag), in meerdere landen

- VS, Californi√´, San Francisco ([Facebook](https://fb.me/1RbYq9H2hOFQ4yi))
- VS, Massachusetts, Boston ([Facebook](https://facebook.com/events/s/pauseai-protest-boston-make-th/6647554948613714/?mibextid=RQdjqZ))
- VK, Parliament Square, Londen ([Aanmelden](https://www.mixily.com/event/4774799330762010477), [Facebook](https://www.facebook.com/events/644748401084077))
- Nederland, Den Haag ([Aanmelden](https://www.mixily.com/event/8536294863402363208))
  <!-- - Isra√´l, Jeruzalem (op 22 oktober, [Aanmelden](https://www.mixily.com/event/2216232092023925957)) -->
  <!-- - Belgi√´, Brussel ([Aanmelden](https://www.mixily.com/event/2708675063120711075)) -->
- Australi√´, Melbourne ([Aanmelden](https://www.mixily.com/event/8471341506387452508))
- Canada, Ottawa (Georganiseerd door Align the World, meld je aan op [Facebook](https://www.facebook.com/events/243643008241929/) of [Eventbrite](https://www.eventbrite.com/e/ai-safety-and-ethics-rally-tickets-725729686027))
  <!-- - Itali√´ ([Aanmelden](https://www.mixily.com/event/7782058162912076825)) -->
  <!-- - Duitsland, Berlijn ([Aanmelden](https://www.mixily.com/event/873099107580787879)) -->
- Denemarken, Kopenhagen ([Facebook](https://www.facebook.com/events/869443424535827))
- Jouw land hier? [Bespreek het op Discord!](https://discord.gg/anXWYCCdH5)

## Waarom we protesteren

AI wordt snel krachtiger, veel sneller dan vrijwel elke AI-wetenschapper heeft voorspeld.
Er worden miljarden ge√Ønvesteerd in AI-capaciteiten, en de resultaten zijn verbluffend.
Nieuwe modellen presteren [beter dan mensen](/sota) in veel domeinen.
Naarmate de capaciteiten toenemen, nemen ook de [risico's](/risks) toe.
Wetenschappers [waarschuwen](https://www.safe.ai/statement-on-ai-risk) zelfs dat AI [de mensheid zou kunnen vernietigen](/xrisk).
Deze ernstige uitkomst lijkt niet alleen mogelijk, maar ook waarschijnlijk, aangezien de gemiddelde waarschijnlijkheidsinschattingen voor deze uitkomsten [vari√´ren van 14% tot 40%](/polls-and-surveys).

We hebben onze leiders nodig om naar deze waarschuwingen te luisteren, maar ze nemen dit onderwerp lang niet zo serieus als ze zouden moeten.
Er wordt wetgeving voor AI-veiligheid opgesteld, maar [geen enkele maatregel zou daadwerkelijk superintelligente AI kunnen voorkomen of vertragen](https://twitter.com/PauseAI/status/1704998018322141496).
[Meer dan 70%](https://www.vox.com/future-perfect/2023/8/18/23836362/ai-slow-down-poll-regulation) wil AI vertragen, en [meer dan 60%](https://www.vox.com/future-perfect/2023/9/19/23879648/americans-artificial-general-intelligence-ai-policy-poll) wil regulering om actief superintelligente AI te voorkomen.
Waarom is er geen wetsvoorstel dat dit daadwerkelijk doet?
Het antwoord is lobbyen: onze politici [ontmoeten voornamelijk CEO's van AI-bedrijven](https://fedscoop.com/sen-schumer-to-host-musk-zuckerberg-and-other-tech-ceos-for-closed-door-ai-forum/), en zij zullen beleidsmaatregelen aandringen die in hun belang zijn.

Op 1 en 2 november zal de allereerste AI Safety Summit plaatsvinden in het VK.
De perfecte gelegenheid om de eerste stappen te zetten naar een verstandige internationale regulering van AI-veiligheid.

## Wat we vragen

- **Beleidsmakers**: Sta bedrijven niet toe om een superintelligentie te bouwen. Regels en hardwarebeperkingen moeten van toepassing zijn voordat de training is begonnen, omdat het zeer moeilijk is om verspreiding te controleren zodra een nieuwe capaciteit is bereikt. We kunnen niet toestaan dat bedrijven potentieel wereldvernietigende AI-modellen trainen. Wetgeving schrijven is moeilijk en kost tijd, maar we hebben misschien niet zo lang, dus werk alsof je leven ervan afhangt. Omdat dat zo is.
- **Bedrijven**: Velen van jullie zijn bang voor wat AI kan doen, maar jullie zitten vast in een race. Wees dus openhartig over het ondersteunen van een pauze in principe. Als je verklaringen ondertekent dat deze technologie ons allemaal zou kunnen doden, laat de wereld dan zien dat je liever niet zou bouwen als het een levensvatbare optie was.
- **Uitgenodigde van de top**: Geef prioriteit aan veiligheid boven economische groei. We weten dat AI onze landen rijker kan maken, maar dat is niet waarom je hier bent opgeroepen. Wees de volwassene in de kamer.

Voor ons volledige voorstel, zie [hier](/proposal).

## Persbericht

_VOOR DIRECTE PUBLICATIE_

### Internationale Protest Roept op tot Stopzetting van Gevaarlijke AI-ontwikkeling

**21 oktober:** [**PauseAI**](https://pauseai.info/) **houdt een internationale** [**protest**](https://pauseai.info/2023-oct) **om beleidsmakers en deelnemers aan de AI Safety Summit aan te sporen om te werken aan een verbod op de creatie van een superintelligente AI. De protestactie zal plaatsvinden in** [**8 landen**](https://pauseai.info/2023-oct) **tegelijkertijd en wordt verwacht de grootste protestactie ooit voor een AI-moratorium te zijn.**

Locaties:

- VS, Californi√´, San Francisco
- VK, Parliament Square, Londen
- Nederland, Den Haag
- Isra√´l, Jeruzalem
- Australi√´, Melbourne
- Canada, Ottawa
- Duitsland, Berlijn
- Denemarken, Kopenhagen

In maart van dit jaar ondertekenden veel vooraanstaande experts [een brief](https://futureoflife.org/open-letter/pause-giant-ai-experiments/#:~:text=We%20call%20on%20all%20AI,more%20powerful%20than%20GPT%2D4.&text=AI%20systems%20with%20human%2Dcompetitive,acknowledged%20by%20top%20AI%20labs.) waarin werd opgeroepen tot een pauze van zes maanden op de ontwikkeling van hun grens-AI-modellen. In mei ondertekenden honderden AI-wetenschappers [een verklaring](https://www.safe.ai/statement-on-ai-risk) waarin stond: ‚ÄúHet mitigeren van het risico op uitsterven door AI moet een wereldwijde prioriteit zijn, naast andere risico's op maatschappelijk niveau zoals pandemie√´n en nucleaire oorlog.‚Äù

Recente [peilingen](https://pauseai.info/polls-and-surveys) hebben aangetoond dat [meer dan 70%](https://www.vox.com/future-perfect/2023/8/18/23836362/ai-slow-down-poll-regulation) van de mensen wil dat de vooruitgang van AI wordt vertraagd, en [meer dan 60%](https://www.vox.com/future-perfect/2023/9/19/23879648/americans-artificial-general-intelligence-ai-policy-poll) wil dat de overheid ingrijpt en voorkomt dat er een superintelligentie wordt gebouwd. Tot nu toe zijn er [geen voorstellen](https://twitter.com/PauseAI/status/1706605169608159458) gedaan die dit zouden doen.

Over twee weken, op 1 en 2 november, zal de allereerste AI Safety Summit plaatsvinden in Bletchley Park, VK. De top zal worden bijgewoond door vooraanstaande AI-wetenschappers, beleidsmakers en leiders uit de industrie. Dit markeert een unieke kans om de eerste stappen te zetten naar internationale regulering van AI-veiligheid. Echter, het VK is niet van plan deze kans te gebruiken om sterke AI-regulering te implementeren. De organisator en de vertegenwoordiger van de premier voor de AI Safety Summit, Matt Clifford, heeft [verklaard](https://twitter.com/PauseAI/status/1709845853668553065) dat ‚Äúhet nu pauzeren van AI-ontwikkeling prematuur zou zijn‚Äù en dat hij [geen ‚Äúharde controles‚Äù](https://twitter.com/matthewclifford/status/1708819574739587356) van de top verwacht.

‚ÄúWe zijn blij dat het VK het voortouw neemt in AI-veiligheid en internationale leiderschap toont‚Äù, zegt Joep Meindertsma, directeur van PauseAI. ‚ÄúMaar we zien niet het niveau van urgentie dat het verdient. In 2020 voorspelden voorspellers [de komst van AI op menselijk niveau in 2055](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/). Vandaag is de [gemiddelde voorspelling](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) 2026. We kunnen geen ramp riskeren door de snelheid van de vooruitgang te onderschatten. We hebben onze politici nodig om aan de veilige kant te blijven. Elk leven is in gevaar. Geen enkel bedrijf zou mogen worden toegestaan om een superintelligentie te bouwen.‚Äù

### Twitter

<WidgetConsent>
<div><blockquote class="twitter-tweet"><p lang="en" dir="ltr">More from London following the world‚Äôs first internationally-coordinated <a href="https://twitter.com/PauseAI?ref_src=twsrc%5Etfw">@PauseAI</a> protest! On Saturday protesters came together in seven cities demanding a ban on the creation of artificial superintelligence, a week before <a href="https://twitter.com/RishiSunak?ref_src=twsrc%5Etfw">@RishiSunak</a>&#39;s AI Safety Summit. Read on ‚¨áÔ∏è <a href="https://t.co/W2vYv4nVIl">pic.twitter.com/W2vYv4nVIl</a></p>&mdash; Alistair Stewart ‚ìã ‚è∏Ô∏è (@alistair___s) <a href="https://twitter.com/alistair___s/status/1716566914242121768?ref_src=twsrc%5Etfw">October 23, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div>
</WidgetConsent>

<WidgetConsent>
<div><blockquote class="twitter-tweet"><p lang="en" dir="ltr">The PauseAI SF protest was a great success. This was the largest AI Safety protest ever in the United States, and it was part of the first and largest global AI Safety protest in history! <br><br>Thank you so much to everyone who made it possible ü©∑ <a href="https://t.co/Yttdpgnrfa">pic.twitter.com/Yttdpgnrfa</a></p>&mdash; Holly ‚è∏Ô∏è Elmore (@ilex_ulmus) <a href="https://twitter.com/ilex_ulmus/status/1715954127954751932?ref_src=twsrc%5Etfw">October 22, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div>
</WidgetConsent>
