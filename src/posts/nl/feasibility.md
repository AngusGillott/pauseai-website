---
title: De haalbaarheid van een pauze
description: Is het mogelijk om AI te pauzeren?
---

<!-- Ik heb bijna helemaal geen bronnen toegevoegd, idealiter zou dat moeten veranderen -->

Het pauzeren van AI is niet onmogelijk.
Het vaststellen van een rode lijn die bepaalt welke soorten technologieën en acties ontwikkeld en uitgevoerd kunnen worden, is iets wat we voortdurend doen.

## Politieke haalbaarheid van een pauze

Sommigen hebben de pauze "radicaal" of "extreem" genoemd, maar zo denkt het publiek er niet over.
Verschillende [peilingen en enquêtes](/polls-and-surveys) hebben aangetoond dat:

- Mensen zich zeer zorgen maken over AI (voornamelijk vanwege veiligheid)
- De overgrote meerderheid (bijna 70%) [steunt een pauze op AI-ontwikkeling](https://www.sentienceinstitute.org/aims-survey-supplement-2023)
- De overgrote meerderheid (>60%) [steunt een internationaal verdrag om AGI te verbieden](https://www.sentienceinstitute.org/aims-survey-supplement-2023)

## Technische handhaafbaarheid van een pauze

De gemakkelijkste manier om grensmodellen op een handhaafbare manier te reguleren, is door [computerkracht te reguleren](https://www.governance.ai/post/computing-power-and-the-governance-of-ai).
We kunnen [GPU's volgen](https://arxiv.org/abs/2303.11341) zoals we elementen volgen die gebruikt worden in de ontwikkeling van nucleaire wapens.
Gelukkig voor ons heeft de computerleveringsketen verschillende knelpunten.
De hardware die nodig is om de grootste modellen te trainen (gespecialiseerde GPU's) wordt geproduceerd door [slechts 1 of 3 bedrijven](https://assets-global.website-files.com/614b70a71b9f71c9c240c7a7/65cb86a0341180453f268f38_SpwF1cBT0AS-m_n20TBXzCF6YprIVM4YRb9PMYWURseU1KtVkSAZJ735esGxNenwVO4Q4wlSUP-_MV3E-SEKp4SIgo1-oNe14CeDHtrb3PLXpJMym5qpWEDbXcf3maEi4yQYfQ-3NP7XgUmkO_4Zekw.jpeg).
Er zijn meerdere monopolies in de leveringsketen voor AI-trainingshardware:

- ASML is het enige bedrijf dat EUV-lithografiemachines produceert
- TSMC is het enige bedrijf dat de meest geavanceerde chips kan vervaardigen
- NVidia is het enige bedrijf dat de meest geavanceerde GPU's ontwerpt

## Macht over bedrijven

Als wat je vreest voornamelijk bedrijven of organisaties zijn, kunnen we ze controleren via 1) wetten, regels en verdragen, of 2) publieke opinie die hen dwingt om zelfregulering toe te passen.

Natuurlijk is de eerste methode de betere, maar reputatie die klanten, investeerders, de moraal van werknemers en werving beïnvloedt, is een reden waarom we protesten organiseren voor sommige AI-laboratoria.
Daarnaast is het belangrijk om te onthouden dat regelgeving bedrijven op lange termijn ten goede kan komen, vanwege regulatoire vangst, het niet verliezen van consumenten als de gevaren zich actualiseren, en het benadelen van concurrenten.
Dus we moeten voorzichtig zijn dat we niet alleen een pauze krijgen, maar dat deze niet wordt opgeheven totdat het daadwerkelijk veilig is om grens-AI verder te ontwikkelen.

## Macht over overheden

Als je bang bent dat overheden je veiligheid niet serieus nemen, is dat een ingewikkelder probleem.
Maar over het algemeen geven politici om het niet verliezen van politieke steun tot op zekere hoogte.
En, belangrijker nog, ze kunnen ook bezorgd zijn over de risico's zonder de enorme vooringenomenheid en juridische verplichtingen die sommige individuen van bedrijven hebben om winst te maximaliseren.

<!-- Ook kunnen buitenlandse staten druk uitoefenen op overheden... opvolgen? -->

Als je denkt dat we regulering van een enkele overheid kunnen krijgen, maar niet een multilateraal verdrag, moet je beseffen dat als overheden kunnen erkennen dat sommige oncontroleerbare technologieën een gevaar vormen voor hun bevolking en uit andere landen kunnen voortkomen, de nieuwe technologieën een nationaal veiligheidsprobleem worden, en de overheden geïnteresseerd raken in het stoppen van andere landen om het ook te ontwikkelen.
Bovendien is het belangrijk te realiseren dat we niet echt veel landen nodig hebben om in de eerste plaats akkoord te gaan met een pauze.
In werkelijkheid kun je een pauze in de ontwikkeling van geavanceerde modellen krijgen door het gewoon in de VS (en zelfs alleen in Californië) te verbieden.
China en de rest van de wereld lijken behoorlijk achter te lopen, en we hoeven ons geen zorgen te maken als hun toetreding tot een verdrag iets later plaatsvindt.

## Soortgelijke historische gevallen

Hoewel elk bewijs van incompetentie of kwade opzet van onze overheden, bedrijven en systemen ons kan verleiden tot een nederlaag-denken, waar coördinatie te moeilijk is, de belangen van de mensen niet goed worden vertegenwoordigd,
en/of worden vertegenwoordigd maar dom zijn, falen we soms om overwinningen te herkennen die we als beschaving door de geschiedenis heen hebben behaald.

Voor empirisch bewijs waarom een verdrag zoals dit mogelijk is, moeten we kijken naar eerdere wereldwijde overeenkomsten.
Of ze nu informeel of formeel zijn, ze zijn door de geschiedenis heen vrij gebruikelijk geweest, voornamelijk om geschillen op te lossen en de mensenrechten vooruit te helpen.
Veel van de eerdere overwinningen, zoals de afschaffing van de slavernij, _hadden ook_ sterke, kortetermijn economische prikkels tegen hen.
Maar dat heeft hen niet gestopt.

Als we zoeken naar soortgelijke moderne voorbeelden van wereldwijde overeenkomsten tegen nieuwe technologieën, kunnen we er veel vinden. Enkele van de belangrijkste waren:

- Het [Montreal Protocol](https://en.wikipedia.org/wiki/Montreal_Protocol), dat de productie van CFC's in alle 197 landen verbood en als gevolg daarvan de wereldwijde emissies van ozonafbrekende stoffen met meer dan 99% sinds 1986 deed afnemen. Dankzij het protocol geneest het gat in de ozonlaag nu, en daarom horen we er niet meer over.
- De [Biological Weapons Convention](https://en.wikipedia.org/wiki/Biological_Weapons_Convention), die biologische en toxine wapens verbood en door 185 staten werd ondertekend.
- De [Chemical Weapons Convention](https://en.wikipedia.org/wiki/Chemical_Weapons_Convention), die chemische wapens verbood en door 193 staten werd ondertekend.
- De [Environmental Modification Convention](https://en.wikipedia.org/wiki/Environmental_Modification_Convention), die weersoorlogsvoering verbood en door 78 staten werd ondertekend.
- Het [Outer Space Treaty](https://en.wikipedia.org/wiki/Outer_Space_Treaty), dat de stationering van massavernietigingswapens in de ruimte verbood, militaire activiteiten op hemellichamen verbood, de vreedzame verkenning en het gebruik van de ruimte wettelijk bindend maakte, en door 114 landen werd ondertekend.
- Het [Non-Proliferation Treaty](https://en.wikipedia.org/wiki/Treaty_on_the_Non-Proliferation_of_Nuclear_Weapons) en een aantal andere internationale overeenkomsten, die cruciaal zijn geweest in het voorkomen van de verspreiding van nucleaire wapens en het bevorderen van het doel van nucleaire ontwapening. Dankzij hen hebben we veel landen kunnen ontmoedigen om nucleaire wapenprogramma's na te streven, het aantal nucleaire arsenalen sinds de jaren '90 verminderd, en nucleaire oorlog gedurende vele decennia vermeden. Allemaal ongelooflijke prestaties.
- De [International Atomic Energy Agency](https://en.wikipedia.org/wiki/International_Atomic_Energy_Agency), die een intergouvernementele organisatie is bestaande uit 178 lidstaten die zich richt op het bevorderen van het vreedzaam gebruik van nucleaire energie en het belemmeren van het gebruik ervan voor militaire doeleinden. Ongeacht of je denkt dat nucleaire energie overgereguleerd is of niet, wordt de IAEA beschouwd als een goed voorbeeld van een internationaal instrument dat we zouden kunnen hebben om de veiligheid van de grootste AI-modellen te evalueren.
- En de [United Nations Declaration on Human Cloning](https://en.wikipedia.org/wiki/United_Nations_Declaration_on_Human_Cloning), die de lidstaten opriep om menselijke kloning in 2005 te verbieden en leidde tot het feit dat veel van hen dat deden. Het is een interessant geval omdat nu, bijna 20 jaar later en zonder een _formeel akkoord_, 60 landen het ofwel volledig of gedeeltelijk hebben verboden en er geen enkel (geverifieerd) geval van een gekloond mens is geweest. Dus op een bepaalde manier suggereert het de mogelijkheid dat veel unilaterale reguleringen voldoende zijn om te voorkomen dat andere gevaarlijke technologieën ook worden ontwikkeld.
<!-- Geneefse Conventies? Ze gaan niet echt over technologie -->

Als je denkt dat AI eigenlijk vergelijkbaar is met andere gevallen waarin we er niet in zijn geslaagd om goede verdragen internationaal te sluiten: alles wat ooit is gebeurd, had een eerste keer.
Er waren bijzonderheden die hen de eerste keer maakten en dat is een reden om [AI-bijzonderheden](#ai-particular-case) aan te pakken.

### Impact van protesten

Het is vrij gebruikelijk dat mensen de effectiviteit van protesten en sociale bewegingen in het algemeen in twijfel trekken.
Natuurlijk zijn er veel gevallen waarin demonstraties geen resultaten opleveren, maar er zijn ook situaties waarin de eisen van de demonstranten worden ingewilligd en het lijkt waarschijnlijk dat die uitkomsten [veroorzaakt zijn door de protesten](https://www.socialchangelab.org/_files/ugd/503ba4_052959e2ee8d4924934b7efe3916981e.pdf).
En [er zijn redenen om te geloven dat AI-activisme vergelijkbare resultaten zou kunnen behalen](https://forum.effectivealtruism.org/posts/WfodoyjePTTuaTjLe/efficacy-of-ai-activism-have-we-ever-said-no).

Als je het idee van protesteren niet leuk vindt, ondernemen we ook [andere acties](/action), zoals het rechtstreeks contacteren van [overheden](/lobby-tips).

## AI bijzonder geval

Als je denkt dat AI verschillend genoeg is van deze gevallen (of zelfs als je dat niet doet), is het nuttig om de bijzondere situatie ervan te analyseren.
De dingen die AI anders maken, maken het misschien niet noodzakelijkerwijs minder regulabel.
Bijvoorbeeld, we zijn [niet bezig met het reguleren van bestaande producten en diensten die mensen al regelmatig gebruiken en waarderen](/proposal), en we zijn niet tegen veel bedrijven die kunnen lobbyen of werknemers die hun baan zouden verliezen als we succesvol zijn. Vrijwel het tegenovergestelde.

Een ander punt in het voordeel is dat het publiek niet partijdig of politiek verdeeld is, maar [verenigd in de steun voor regulering](https://drive.google.com/file/d/1n0pXDBuIcb01tW4TQdP1Mb5aAiFDvWk0/view).
Desondanks moeten we voorzichtig zijn om ze niet af te schrikken, hun perspectieven te horen, en te zien op welke specifieke manieren ze geholpen kunnen worden door een pauze op basis van waar ze om geven. Aangezien veel mensen hun mening nog niet hebben gevormd over welk type regulering ze steunen.

Als het gaat om AI-risico's, lijken het publiek en de experts [bezorgd over de risico's en geïnteresseerd in regulering](https://polls-and-surveys).
De politici, op basis van de [beleid die worden aangenomen en waaraan ze werken](https://www.bloomberg.com/news/articles/2024-03-13/regulate-ai-how-us-eu-and-china-are-going-about-it), de [toppen die ze organiseren](/summit), en de [verklaringen die ze geven](/quotes)<!--we moeten die pagina afmaken-->, lijken ook behoorlijk bezorgd.
Zelfs een recent [door de Amerikaanse overheid in opdracht gegeven rapport](https://time.com/6898967/ai-extinction-national-security-risks-report/) beveelt, onder meerdere voorstellen, verschillende soorten pauzes in de AI-ontwikkeling aan om risico's voor de nationale veiligheid en de mensheid als geheel te voorkomen.

Dit alles gebeurt terwijl PauseAI nog vrij jong is en de meeste mensen nog niet van de meeste risico's hebben gehoord.
Als we bijvoorbeeld bewustzijn en consensus over existentiële risico's zouden vergroten, zouden we de potentie hebben om meer mainstream te worden, aangezien vrijwel niemand wil sterven of dat de wereld eindigt.
Dat is niet iets wat zelfs in het beste belang is van de meest egoïstische bedrijven, overheden en mensen.

Zelfs als het tijd kost, zal de manifestatie van de problemen die AI's in de komende jaren met zich mee zullen brengen, het bewustzijn ervan versterken en uiteindelijk meer en meer regulering uitlokken.
In het geval dat we niet zo snel als we willen een pauze krijgen, zou massale werkloosheid en allerlei incidenten de meeste mensen op dezelfde lijn kunnen brengen, hetzij geleidelijk of plotseling, en de mensen die een pauze niet serieus zouden hebben overwogen, daadwerkelijk doen.
Daarom is het belangrijk om onze potentie om te slagen niet te baseren op kortetermijnresultaten, maar altijd voorbereid te zijn op nieuwe aanhangers en bondgenoten, en klaar te zijn om politici te begeleiden bij het implementeren van onze voorstellen in het geval er een waarschuwingsschot plaatsvindt.

## Nevenvoordelen

Pleiten voor een pauze heeft andere positieve effecten buiten het bereiken ervan.
Het informeren van het publiek, techmensen en politici over de risico's helpt andere interventies die gericht zijn op het veilig maken van AI's en AI veilig.
Het zorgt ervoor dat mensen meer belang hechten aan het technische, politieke en communicatieve werk dat in AI-veiligheid en AI-ethiek gaat, wat uiteindelijk betekent dat er meer financiering en banen in gaan, in de verwachting van betere resultaten.

Het zou niet alleen nieuwe mensen en middelen naar nieuwe interventies brengen, maar het zou ook helpen om technische en beleidsinitiatieven er "redelijker" uit te laten zien en hun kansen op ondersteuning te vergroten.

Bovendien zou het mensen enigszins kunnen voorbereiden op de gevaren, hen leren hoe ze AI ethischer kunnen gebruiken, en zelfs hen kunnen overtuigen om niet te investeren of te werken aan grens- en onveilige projecten.

## Geef niet toe aan pessimisme

We begrijpen waar de pessimistische overtuigingen over sterke regulering vandaan komen en dat het niet gemakkelijk zal zijn.
Maar het is ook niet gemakkelijk om de toekomst te voorspellen, en dit artikel probeert tegen de overmoed van onze machteloosheid te pleiten, aangezien het enige wat dat kan doen, een zelfvervullende profetie is.

Het enige gemakkelijke om te doen is opgeven, [het is de gemakkelijke uitweg](/psychology-of-x-risk#difficult-to-act-on).
Want als er niets is dat we kunnen doen, is er niets dat we zouden moeten doen.
Maar we zouden niet moeten opgeven zonder het zelfs maar te proberen.
Dit is eigenlijk onze beste kans om impact te hebben op de wereld en de toekomst van onze beschaving.

## Beslissingstheorie zegt: probeer het toch

Zelfs als je gelooft dat een pauze vrij onwaarschijnlijk is en je geeft niet om de andere voordelen, tenzij je de grootste risico's niet gelooft of betere strategieën in gedachten hebt, raden we je aan om [je aan te sluiten](/join). Steek je hoofd niet in het zand en wacht niet om te sterven of gered te worden, je kunt ons helpen dit te bereiken!
