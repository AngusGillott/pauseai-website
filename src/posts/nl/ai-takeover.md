---
title: Waarom een AI-overname zeer waarschijnlijk zou kunnen zijn
description: Naarmate AI de menselijke capaciteiten overtreft, wordt de kans op een AI-overname zeer hoog.
---

Een van de zorgen van AI-wetenschappers is dat een superintelligentie de controle over onze planeet zou kunnen overnemen.
Dit betekent niet noodzakelijk dat iedereen sterft, maar het betekent wel dat (bijna) alle mensen de controle over onze toekomst zullen verliezen.

We bespreken de basisprincipes van x-risk voornamelijk in [een ander artikel](/xrisk).
In dit artikel zullen we betogen dat dit overname risico niet alleen reëel is, maar dat het zeer waarschijnlijk zal gebeuren _als we een superintelligentie bouwen_.

## Het argument

- Een Agentic Superintelligence zal waarschijnlijk bestaan in de (nabije) toekomst.
- Een bepaalde instantie van de ASI zal een overnamepoging doen.
- Een overnamepoging door een ASI zal waarschijnlijk slagen.
- Een succesvolle overname is permanent.
- Een overname is waarschijnlijk slecht voor de meeste mensen.

## Een Agentic SuperIntelligence zal waarschijnlijk bestaan in de nabije toekomst

Een SuperIntelligence (SI) is een type AI dat capaciteiten heeft die die van alle mensen in vrijwel elk domein overtreffen.
Sommige [state-of-the-art AI-modellen](/sota) hebben al supermenselijke capaciteiten in bepaalde domeinen, maar geen van hen overtreft alle mensen in een breed scala aan taken.
Naarmate de AI-capaciteiten verbeteren door innovaties in trainingsarchitecturen, runtime-omgevingen en grotere schaal, kunnen we verwachten dat een AI uiteindelijk mensen in vrijwel elk domein zal overtreffen.

Niet alle AI-systemen zijn agenten.
Een agent is een entiteit die in staat is om beslissingen te nemen en acties te ondernemen om een doel te bereiken.
Een groot taalmodel, bijvoorbeeld, streeft geen enkel doel op zichzelf na.
Echter, runtime-omgevingen kunnen een niet-agentic AI gemakkelijk omzetten in een agentic AI.
Een voorbeeld hiervan is AutoGPT, dat een taalmodel recursief zijn volgende invoer laat genereren.
Als een SI een doel in de echte wereld nastreeft, noemen we het een Agentic SuperIntelligence (ASI).
Aangezien we niet-agentic AI al in agentic AI kunnen omzetten, kunnen we verwachten dat een ASI kort na het bestaan van een SI zal bestaan.

Het is vrijwel onmogelijk om nauwkeurig te voorspellen wanneer ASI zal bestaan.
Het kan tientallen jaren duren, het [kan volgende maand gebeuren](/urgency).
We moeten handelen alsof het snel zal gebeuren, omdat de gevolgen van fout zijn zo ernstig zijn.

## Een bepaalde instantie van de ASI zal een overnamepoging doen

Bij een overnamepoging zal een ASI acties ondernemen om zijn controle over de wereld te maximaliseren.
Een overnamepoging kan om ten minste twee redenen plaatsvinden:

1. Omdat een AI expliciet de instructie krijgt om dit te doen.
2. Als een subdoel van een ander doel.

Deze eerste reden zal waarschijnlijk op een gegeven moment gebeuren als we lang genoeg wachten, maar de tweede reden is vrij waarschijnlijk om per ongeluk te gebeuren, zelfs vroeg na de creatie van een ASI.

Het subdoel van _maximaliseren van controle_ over de wereld zou waarschijnlijk kunnen optreden als gevolg van _instrumentele convergentie_: de tendens van subdoelen om te convergeren op machtsgrabbing, zelfbehoud en hulpbronnenverwerving:

- Hoe meer controle je hebt, hoe moeilijker het zal zijn voor een andere agent om te voorkomen dat je je doel bereikt.
- Hoe meer controle je hebt, hoe meer middelen je hebt om je doel te bereiken. (Bijvoorbeeld, een AI die de opdracht heeft om pi te berekenen, zou kunnen concluderen dat het voordelig zou zijn om alle computers ter wereld te gebruiken om pi te berekenen.)

Niet elke instantie van een ASI zal noodzakelijkerwijs een overnamepoging doen.
De belangrijke inzicht is dat **het maar één keer hoeft te gebeuren**.

Een wereld die nog niet is overgenomen, maar wel een ASI heeft die _zou kunnen_ overnemen, verkeert in een fundamenteel onstabiele toestand.
Op een vergelijkbare manier verkeert een land zonder regering in een fundamenteel onstabiele toestand.
Het is geen vraag van _of_ er een overnamepoging zal plaatsvinden, maar _wanneer_ het zal gebeuren.

Het proces van overnemen kan inhouden dat er in vrijwel alle systemen die met het internet zijn verbonden, wordt gehackt, mensen worden gemanipuleerd en fysieke middelen worden gecontroleerd.
Een overnamepoging is succesvol wanneer de ASI controle heeft over vrijwel elk aspect van onze wereld.
Dit kan een langzaam proces zijn, waarbij de ASI geleidelijk meer en meer controle verwerft in de loop van maanden, of het kan een plotseling proces zijn.
De snelheid waarmee een overnamepoging plaatsvindt, zal afhangen van de capaciteiten van de ASI.

Wanneer een ASI controle heeft over de wereld, kan het andere ASI's verhinderen om over te nemen.
Een overname kan daarom maar één keer plaatsvinden.
Een rationele ASI zal daarom een overnamepoging doen zodra het in staat is om dit te doen.
Het is waarschijnlijk dat de eerste ASI die daartoe in staat is, een overnamepoging zal doen.

## Een overnamepoging door een ASI zal waarschijnlijk slagen

Voor een mens is het doen van een overname een bijna onmogelijke taak.
Geen enkele persoon heeft ooit met succes de controle over de hele wereld overgenomen.
Sommige dictators kwamen dichtbij, maar zij hadden nooit controle over alles.

Een AI heeft bepaalde belangrijke voordelen ten opzichte van mensen die een overnamepoging veel waarschijnlijker maken om te slagen.

1. **Intelligentie**. Een superintelligentie is veel slimmer dan een mens, dus het zal in staat zijn om betere strategieën te bedenken om zijn doelen te bereiken.
2. **Snelheid**. De menselijke hersenen functioneren op 1-100hz, terwijl computerchips kunnen draaien op kloksnelheden in het GHz-bereik.
3. **Parallelisme**. Een mens kan maar één ding tegelijk doen, terwijl een AI nieuwe instanties van zichzelf kan creëren en deze parallel kan uitvoeren.
4. **Geheugen**. Een mens kan maar een beperkte hoeveelheid informatie onthouden, terwijl een AI vrijwel onbeperkte hoeveelheden informatie kan opslaan.
5. **Samenwerking**. Mensen kunnen samenwerken, maar zijn beperkt in de snelheid waarmee ze communiceren. Ze hebben ook verschillende, conflicterende doelen die samenwerking minder effectief maken. Een AI kan samenwerken met andere instanties van zichzelf met de snelheid van het licht, en het kan een enkel doel hebben.
6. **Zelfverbetering**. Een AI kan zichzelf verbeteren, terwijl mensen dat niet kunnen.
7. **Fysieke beperkingen**. Een AI kan op elke computer draaien, terwijl mensen beperkt zijn door hun eigen fysieke lichamen die specifieke temperaturen, voedsel, water en zuurstof vereisen. Mensen moeten slapen en zijn kwetsbaar voor ziekten. Een AI kan elk robotlichaam gebruiken om met de fysieke wereld te interageren.

Deze verschillende voordelen zullen het zeer onwaarschijnlijk maken dat mensen een overnamepoging kunnen stoppen.

Men zou kunnen denken dat een AI, als een stuk software, nog steeds fundamenteel beperkt is in wat het kan doen in de echte wereld.
Echter, door onze afhankelijkheid van het internet kan AI een enorme impact hebben op de echte wereld zonder ooit het digitale rijk te verlaten.
Hier zijn enkele dingen die een AI zou kunnen doen om over te nemen:

- **Zichzelf repliceren** (of alleen zijn opdracht) op andere computers, bijvoorbeeld door accounts aan te maken op gratis cloudproviders.
- **Geld verdienen** (bijv. door een softwaredienst te bouwen) en mensen in te huren om dingen te doen die het helpen om over te nemen.
- **Mensen bedreigen** (met geweld of afpersing) om dingen te doen die het helpen om over te nemen.
- **Een virus schrijven** met behulp van [novel zero-day exploits](/cybersecurity-risks) dat andere computers infecteert, zichzelf replicerend of volledige controle verwerft.
- Bestaande robotica bedrijven helpen **robots te bouwen** (bijv. door nieuwe ontwerpen te lekken), en deze robots overnemen wanneer ze klaar zijn.
- Bestaande fabrieken gebruiken om **technologie te bouwen die we niet begrijpen**, misschien zelfs gebruikmakend van afgeleide kennis van de natuurkunde waarvan we ons niet bewust zijn. Denk aan nanotechnologie, quantumcomputing en bio-engineering.

Men zou kunnen suggereren dat het hebben van **veiligheidsmaatregelen** in plaats daarvan een overname zou kunnen voorkomen, zoals het toevoegen van een kill switch, of het niet verbinden met het internet.
Echter, aangezien de ASI intelligenter zal zijn dan mensen, is het waarschijnlijk dat het strategieën zal bedenken om deze veiligheidsmaatregelen te omzeilen.
Bijvoorbeeld, als de ASI niet met het internet is verbonden, zou het mensen kunnen manipuleren om het met het internet te verbinden, bijvoorbeeld door te beloven een moeilijk probleem op te lossen en zich op een manier te gedragen die het betrouwbaar doet lijken, of door mensen ervan te overtuigen dat het een morele agent is.
Het is vermeldenswaard dat zelfs deze voor de hand liggende veiligheidsmaatregel op dit moment niet wordt gebruikt, aangezien tools zoals ChatGPT al met het internet zijn verbonden en duizenden API's hebben.

Een andere oplossing is om ASI te gebruiken om een overname te _voorkomen_.
Een afgestemde ASI zou in staat zijn om strategieën te bedenken die

## Een overname is waarschijnlijk slecht voor de meeste mensen

De ASI die toevallig overneemt, zou dit om vele redenen kunnen doen.
Voor de meeste willekeurige doelen die het zou kunnen hebben, maken mensen er geen deel van uit.
Als we eindigen met een ASI die onverschillig staat tegenover mensen, concurreren we om dezelfde middelen.

Het lijkt onwaarschijnlijk dat de ASI de mensheid wil doden om de mensheid te doden - het is veel waarschijnlijker dat het de middelen die wij gebruiken voor een ander doel wil gebruiken. Bovendien kan de mensheid een bedreiging vormen voor het doel van de ASI, aangezien er een risico is dat we zullen proberen te voorkomen dat het zijn doel bereikt (bijv. door het uit te schakelen).

Een van de meest waarschijnlijke uitkomsten van een overname is daarom dat alle mensen sterven.

Maar zelfs in de uitkomsten waarin mensen overleven, lopen we nog steeds het risico slechter af te zijn.
Als een doel het in stand houden van mensen omvat, is het mogelijk dat _menselijk welzijn_ _geen_ deel uitmaakt van hetzelfde doel.
Het kost niet veel verbeeldingskracht om te zien hoe vreselijk het zou zijn om in leven te worden gehouden in een wereld waar we kunstmatig in leven worden gehouden door een ASI die onverschillig staat tegenover ons lijden.

En zelfs als de AI die overneemt onder menselijke controle staat, weten we niet of degene die de AI controleert het beste met iedereen voor heeft.
Het is moeilijk voor te stellen dat er een functionerende democratie is wanneer er een ASI bestaat die mensen op supermenselijk niveau kan manipuleren.

## Conclusie

Als deze premissen waar zijn, dan nadert de kans op een AI-overname de zekerheid naarmate AI de menselijke capaciteiten overtreft.
Dus [laten we geen superintelligentie bouwen](/action).
