---
title: PauseAI protest @ Melbourne - 16 juni
description: Sluit je aan bij PauseAI voor een aanstaande vreedzame protestactie in het Melbourne Convention and Exhibition Centre (MCEC) waar Sam Altman een lezing zal geven in Melbourne.
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

<WidgetConsent>
<div>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Vandaag hebben we geprotesteerd in Melbourne, waar OpenAI&#39;s Sam Altman sprak. OpenAI heeft als doel een superintelligentie te bouwen, wat een serieuze kans heeft om iedereen op aarde te doden. We eisen dat onze regeringen ingrijpen en <a href="https://twitter.com/hashtag/PauseAI?src=hash&amp;ref_src=twsrc%5Etfw">#PauseAI</a>.<br><br>Persbericht: <a href="https://t.co/xu7XXTUUyT">https://t.co/xu7XXTUUyT</a> <a href="https://t.co/HtYymXpqjf">https://t.co/HtYymXpqjf</a></p>&mdash; PauseAI (@pause_ai_info) <a href="https://twitter.com/pause_ai_info/status/1669809871867240451?ref_src=twsrc%5Etfw">16 juni 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</WidgetConsent>

Sluit je aan bij #PauseAI voor een aanstaande vreedzame protestactie in het Melbourne Convention and Exhibition Centre (MCEC) waar Sam Altman een lezing zal geven.

- Datum & Tijd: Vrijdag 16 juni, 14:00 AEST
- Locatie: Hoofdingang van MCEC, 1 Convention Centre Place, South Wharf, VIC 3006, Australië
- Protesttijden: 13:30 tot 15:00 (aankomsttijd) & 16:30 en later (vertrektijd)
- Logistiek: Neem borden en flyers mee, er is geen vergoeding vereist om deel te nemen, het lidmaatschap van Startup Victoria is momenteel gratis

Sluit je bij ons aan om je stem te laten horen voor AI-veiligheid en een verschil te maken. Sluit je aan bij #PauseAI's [Discord-server](https://discord.gg/2XXWXvErfA), het #australia-kanaal en AGI Moratorium's Slack, [#λ-australia](https://www.campaignforaisafety.org/r/2b0991d9?m=4045bfdd-2b52-4fa2-b4c5-0d8adb4aac63) voor meer discussies.

## Persbericht

Op vrijdag 16 juni zullen vrijwilligers van de nieuwe [PauseAI](http://pauseai.info) beweging samenkomen in het Melbourne Convention and Exhibition Centre om de Australische regering te verzoeken het voortouw te nemen in het pauzeren van de ontwikkeling van krachtigere en gevaarlijkere AI-systemen.

Een snel toenemend aantal AI-experts [ondertekende een verklaring](https://www.safe.ai/statement-on-ai-risk) vorige week die luidt:

> "Het mitigeren van het risico op uitsterven door AI zou een wereldwijde prioriteit moeten zijn, naast andere risico's op maatschappelijke schaal zoals pandemieën en nucleaire oorlog."

Deze verklaring is ondertekend door vrijwel alle AI-laboratoria (OpenAI, Google DeepMind, Anthropic) en honderden AI-wetenschappers, waaronder Geoffrey Hinton, de "Godfather of AI".

AI-veiligheidsonderzoekers hebben geen consensus bereikt over hoe groot het risico van menselijke uitsterving zal zijn.
Resultaten van de ["Existential risk from AI survey"](https://forum.effectivealtruism.org/posts/8CM9vZ2nnQsWJNsHx/existential-risk-from-ai-survey-results) tonen aan dat de schattingen variëren van 2% tot 98%, met een gemiddelde van 30%.

De demonstranten dringen er bij de Australische regering op aan het voortouw te nemen in wereldwijde AI-veiligheid en de ontwikkeling van gevaarlijkere AI-systemen te pauzeren.
Ze vragen ook om prioriteit te geven aan de pauze op de [AI Safety Summit](https://pauseai.info/summit), die door het VK wordt georganiseerd en later in 2023 zal plaatsvinden.

Het pauzeren van de AI-ontwikkeling is een radicaal andere benadering van veiligheid dan wat de CEO's van AI-laboratoria zoals Sam Altman voorstellen.
OpenAI gelooft dat ["het intuïtief riskant en moeilijk zou zijn om de creatie van superintelligentie te stoppen"](https://openai.com/blog/governance-of-superintelligence), dus zij streven verdere ontwikkeling naar superintelligentie na.

> "We hebben een keuze: riskeren we alles om een superintelligentie te bouwen waar het publiek nooit over is geraadpleegd, of stoppen we terwijl we nog kunnen?" - PauseAI-demonstranten

> "AI-bedrijven zetten alles op het spel; we zien al de schade, en het zal veel erger worden. Technologische ontwikkeling is niet onvermijdelijk, en pauzeren moet als een haalbare optie worden beschouwd. We kunnen de toekomst niet overlaten aan een paar CEO's die erkennen dat ze bereid zijn de mensheid voor hun dromen te riskeren. We verdienen allemaal een stem in onze toekomst, en een wereldwijde pauze geeft ons die kans."

> "Ondanks het erkennen van de gevaren van voortdurende AI-ontwikkeling, gebruiken deze bedrijven het slechts als een excuus om door te gaan, en lijken ze te weigeren deze gevaarlijke macht vrijwillig op te geven. In dergelijke situaties is wereldwijde samenwerking om deze gevaarlijke ontwikkeling in te perken cruciaal, zodat we ervoor zorgen dat technologische ontwikkeling ten goede komt aan iedereen."

> "We hebben misschien niet de luxe van tijd. AI-ontwikkelingen gebeuren in een razend tempo, en we moeten nu handelen om de ergste scenario's te voorkomen. De top in de herfst zou zelfs te laat kunnen zijn om het ergste te voorkomen. We hebben regeringen nodig om de AI-ontwikkeling nu te pauzeren."

De PauseAI-demonstranten hebben concrete [agendasuggesties](/summit) en [beleidsvoorstellen](/proposal) voor de top.

Voor meer informatie, bezoek [PauseAI.info](http://pauseai.info).

## Contact

- Michael Huang ([Twitter](https://twitter.com/michhuan))
