---
title: PauseAI kaarsenwake @ VN HQ NYC, 3 juni
---

- Kaarsenwake om bewustzijn te creëren over het existentiële risico van AI.
- 3 juni, 19:30 tot 21:00. De zon gaat hier onder om 20:15.
- Hoofdkantoor van de Verenigde Naties in New York City.
- [Aanmelden](https://forms.gle/hsVetUDx3R1w6yj59)

## Persbericht

Op zaterdag 3 juni, bij zonsondergang, zal er een kaarsenwake plaatsvinden voor de Verenigde Naties.
De wake is een teken van hoop, zodat mensen samen kunnen komen om te handelen in het licht van een groeiende existentiële bedreiging.
Vrijwilligers van de nieuwe [PauseAI](http://pauseai.info) beweging zullen daar samenkomen om regeringen aan te sporen een top te organiseren om de ontwikkeling van deze gevaarlijke technologie te stoppen.

De helft van de AI-onderzoekers [gelooft](https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/) dat er een kans van 10% of meer is dat de uitvinding van supermenselijke AI het einde van de mensheid betekent. Zou je in een vliegtuig stappen als de helft van de vliegtuigbouwers dacht dat er een kans van 10% was dat het zou neerstorten?

Voorbeelden van prominente mensen die waarschuwen voor de gevaren van AI zijn Prof. [Geoffrey Hinton](https://www.reuters.com/technology/ai-pioneer-says-its-threat-world-may-be-more-urgent-than-climate-change-2023-05-05/) en Prof. [Yoshua Bengio](https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/), beide Turing Award-winnaars en pioniers van de meest succesvolle AI-methoden van vandaag. Niet alleen wetenschappers, maar ook leiders van AI-bedrijven zelf maken zich zorgen over dit gevaar:

- Sam Altman (CEO van OpenAI, het bedrijf achter ChatGPT): ["De ontwikkeling van supermenselijke machine-intelligentie is waarschijnlijk de grootste bedreiging voor het voortbestaan van de mensheid."](https://blog.samaltman.com/machine-intelligence-part-1)
- Elon Musk (mede-oprichter van OpenAI): ["AI heeft het potentieel voor beschaving vernietiging."](https://www.inc.com/ben-sherry/elon-musk-ai-has-the-potential-of-civilizational-destruction.html)
- Bill Gates (mede-oprichter van Microsoft, eigenaar van 50% van OpenAI): ["AI zou kunnen besluiten dat mensen een bedreiging zijn."](https://www.denisonforum.org/daily-article/bill-gates-ai-humans-threat/)
- Jaan Tallinn (hoofdinvesteerder bij Anthropic, bouwers van Claude): ["Ik heb nog niemand in AI-laboratoria ontmoet die zegt dat het risico [van het trainen van een next-gen model] minder dan 1% is dat de planeet verwoest wordt. Het is belangrijk dat mensen weten dat levens op het spel staan."](https://twitter.com/liron/status/1656929936639430657)

De vooruitgang in het AI-landschap heeft de verwachtingen overtroffen. In 2020 werd geschat dat een AI-systeem in 2050 universitaire toelatingsexamens zou halen. Dit doel werd in maart 2023 bereikt door OpenAI's GPT-4. Deze AI heeft een [verbaal IQ van 155](https://bgr.com/tech/chatgpt-took-an-iq-test-and-its-score-was-sky-high/), spreekt 23 talen, kan programmeren en [kan mensen misleiden](https://www.theinsaneapp.com/2023/03/gpt4-passed-captcha-test.html). Gelukkig heeft GPT-4 nog steeds beperkingen. Zo kan het niet effectief [hacken of computervirussen schrijven](https://pauseai.info/cybersecurity-risks), maar het is mogelijk dat deze vaardigheden slechts enkele innovaties verwijderd zijn. Gezien het huidige tempo van AI-investeringen, komt dit punt [snel dichterbij](https://pauseai.info/urgency).

Deze enorme en onverwachte sprongen in mogelijkheden hebben veel experts ertoe aangezet om een pauze in de ontwikkeling van AI te verzoeken via een [open brief](https://futureoflife.org/open-letter/pause-giant-ai-experiments/) gericht aan grote AI-bedrijven. De brief is meer dan 27.000 keer ondertekend, voornamelijk door AI-onderzoekers en technologie-experts. Een pauze is nodig om te werken aan AI-wetgeving, het AI-afstemmingsprobleem aan te pakken en als samenleving aan deze nieuwe technologie aan te passen. Een [recent onderzoek](https://forum.effectivealtruism.org/posts/EoqeJCBiuJbMTKfPZ/unveiling-the-american-public-opinion-on-ai-moratorium-and) in de Verenigde Staten toont aanzienlijke steun voor een pauze, met meer dan 60% van het publiek voorstander. Helaas lijkt het erop dat bedrijven niet bereid zijn vrijwillig hun concurrentiepositie in gevaar te brengen door te stoppen. Deze AI-bedrijven zijn verwikkeld in een race naar de bodem, waarbij veiligheid steeds meer op de achtergrond raakt ten opzichte van het verbeteren van mogelijkheden. Daarom moet de pauze door regeringen worden opgelegd. Het implementeren van een nationale pauze is ook uitdagend, aangezien landen redenen hebben om niet de eerste te zijn die pauzeert. Daarom is een internationale oplossing nodig: een top. PauseAI roept onze regeringen op om die top te organiseren.

Voor meer informatie, bezoek [PauseAI.info](http://pauseai.info).
