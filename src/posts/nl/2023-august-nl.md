---
title: PauseAI protest @ Den Haag, Nederland - 11 augustus
description: We organiseren een protest om een pauze te eisen op gevaarlijke AI-ontwikkeling.
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

<WidgetConsent>
<div>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">We protested in The Hague, Netherlands to ask our government to prioritise mitigation of AI risks. We had a few speeches, talked to people on the streets, handed out flyers and had a good time!<br><br>Check out the press release (EN + NL) for more information: <a href="https://t.co/Dd7CXHlajc">https://t.co/Dd7CXHlajc</a> <a href="https://t.co/T306vZD974">pic.twitter.com/T306vZD974</a></p>&mdash; PauseAI ‚è∏ü§ñ (@PauseAI) <a href="https://twitter.com/PauseAI/status/1690290512643719168?ref_src=twsrc%5Etfw">August 12, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</WidgetConsent>

- PauseAI protest
- Waar: Wijnhaven, Den Haag
- Wanneer: 11 augustus 2023, 16:00 - 17:00

## Waarom we protesteren

AI wordt snel krachtiger, veel sneller dan vrijwel elke AI-wetenschapper heeft voorspeld.
Er worden miljarden ge√Ønvesteerd in AI-capaciteiten, en de resultaten zijn verbluffend.
Nieuwe modellen presteren [beter dan mensen](/sota) in veel domeinen.
Naarmate de capaciteiten toenemen, nemen ook de [risico's](/risks) toe.
Wetenschappers [waarschuwen](https://www.safe.ai/statement-on-ai-risk) zelfs dat AI [de mensheid zou kunnen vernietigen](/xrisk).

Onze politici nemen dit onderwerp lang niet zo serieus als ze zouden moeten.
We hebben onze leiders nodig om naar deze waarschuwingen te luisteren.
We hebben ze nodig om actie te ondernemen en een [pauze in te voeren](/proposal) om deze zelfmoordrace te stoppen.

We willen dat de Nederlandse regering:

- AI-veiligheidsexperts uitnodigt om het parlement te informeren over deze risico's
- Een debat inplant over de existenti√´le risico's van AI
- Voorbereidingen voor de AI-veiligheidssummit later dit jaar prioriteit geeft en een leidende rol aanneemt in het werken aan effectief beleid
- Internationaal samenwerkt om voldoende veiligheidsmaatregelen op mondiale schaal te co√∂rdineren

## Agenda

- 12:00 - 16:00 Voorbereiding van borden in workshop (alleen voor de echte enthousiastelingen, neem contact met ons op als je erbij wilt zijn!)
- 16:00 Toespraken + protest + flyeren
- 17:00 Drankjes @ nabijgelegen caf√©

## Contact

- Joep Meindertsma ([twitter](https://twitter.com/joepmeindertsma), [email](mailto:joep@ontola.io))

## Persbericht (EN): PauseAI Calls on Dutch Government to Prevent Human-Threatening, AI-Related Disasters

Op vrijdag 11 augustus om 16:00 uur komt een groep bezorgde individuen samen bij het Ministerie van Binnenlandse Zaken onder de naam [PauseAI](http://pauseai.info) om de ontwikkelingen op het gebied van (generatieve) AI aan te kaarten. Zij dringen er bij de regering op aan actie te ondernemen om de ontwikkeling van krachtige en potentieel gevaarlijke kunstmatige intelligentie te pauzeren.

Tot nu toe heeft de Nederlandse regering geen stappen ondernomen om de existenti√´le bedreiging van AI aan te pakken. Er is geen reactie gekomen op waarschuwingen en uitspraken van entiteiten zoals de [VN](https://www.linkedin.com/feed/update/urn:li:activity:7075767810336923648), de premier van het [Verenigd Koninkrijk](https://www.theguardian.com/technology/2023/may/25/no-10-acknowledges-existential-risk-ai-first-time-rishi-sunak?) (waar een top over dit onderwerp gepland staat voor de herfst), en [AI-experts](https://nos.nl/op3/artikel/2012979-wetenschappers-waarschuwen-voor-kunstmatige-intelligentie), zelfs niet na een [motie](https://www.parlementairemonitor.nl/9353000/1/j9vvij5epmj1ey0/vm1rshv2ulz5) in de Tweede Kamer die eerder dit jaar tot actie aanzette.

"[Wetenschappers](https://www.safe.ai/statement-on-ai-risk) trekken aan de bel: AI kan het einde betekenen van de mensheid. Experts schatten zelfs een [30% kans](https://forum.effectivealtruism.org/posts/8CM9vZ2nnQsWJNsHx/existential-risk-from-ai-survey-results) dat dit gebeurt. AI-bedrijven gaan voortvarend te werk en riskeren al onze levens, terwijl de regulering hopeloos achterblijft." - Joep Meindertsma, CEO van softwarebedrijf Ontola en oprichter van PauseAI.

De zorgen over de risico's die samenhangen met AI groeien wereldwijd snel. Deze week publiceerde onderzoeksbureau Axios de resultaten van een opiniepeiling onder inwoners van de Verenigde Staten, waaruit bleek dat 86% van de respondenten zich zorgen maakt over catastrofale AI-risico's.

"De VS houdt senaatshoorzittingen waar AI-experts bespreken hoe AI het einde van de mensheid kan betekenen. Waarom wordt dit onderwerp genegeerd in de Nederlandse politiek? Vooral gezien het feit dat Nederland een sleutelrol speelt in de chipleveringsketen, dankzij ASML. Daarom kan het ook een cruciale rol spelen in AI-computergestuurde governance. Alle levens staan op het spel!" - Joep Meindertsma

PauseAI roept de Nederlandse regering op om:

- AI-veiligheidsexperts uit te nodigen om het parlement te informeren over deze risico's
- Een parlementair debat in te plannen over de existenti√´le risico's van geavanceerde kunstmatige intelligentie
- Voorrang te geven aan de voorbereidingen voor de voorgestelde AI-top in het Verenigd Koninkrijk later dit jaar en een leidende rol te nemen in effectief beleid. De activisten hebben concrete [voorstellen](https://pauseai.info/summit) en [beleidsidee√´n](https://pauseai.info/proposal) voor de komende AI-top.
- Internationaal samen te werken om een adequaat pakket maatregelen op mondiale schaal te implementeren, inclusief een zogenaamde AI-pauze.

Voor meer informatie, bezoek [PauseAI.info](http://pauseai.info). Contact: Joep Meindertsma ([twitter](https://twitter.com/joepmeindertsma), [email](mailto:joep@ontola.io)) & Ruben Dieleman ([email](mailto:ruben@existentialriskobservatory.org))

## Persbericht (NL): PauseAI roept overheid op tot het voorkomen van mensbedreigende, AI-gerelateerde rampen

Op vrijdag 11 augustus om 16.00 komt een groep mensen samen die zich zorgen maken over de ontwikkelingen op het gebied van (generatieve) AI bij het Ministerie van Binnenlandse Zaken onder de naam [PauseAI](http://pauseai.info). Zij roepen de regering op zich in te spannen voor een pauze van de ontwikkeling van krachtige en mogelijk gevaarlijke kunstmatige intelligentie.

Tot nu toe heeft de Nederlandse regering echter geen actie ondernomen tegen de existenti√´le bedreiging van AI. Er is nog niet [gereageerd](https://www.linkedin.com/feed/update/urn:li:activity:7075767810336923648) op waarschuwingen en uitspraken van onder meer de [VN](https://www.linkedin.com/feed/update/urn:li:activity:7075088560508284928), de premier van het [Verenigd Koninkrijk](https://www.theguardian.com/technology/2023/may/25/no-10-acknowledges-existential-risk-ai-first-time-rishi-sunak?) (waar in het najaar een top wordt georganiseerd over dit onderwerp) en [experts op het gebied van AI](https://nos.nl/op3/artikel/2012979-wetenschappers-waarschuwen-voor-kunstmatige-intelligentie). Ook niet nadat eerder dit jaar een [motie](https://www.parlementairemonitor.nl/9353000/1/j9vvij5epmj1ey0/vm1rshv2ulz5) in de Tweede Kamer daartoe aanspoorde.

"[Wetenschappers](https://www.safe.ai/statement-on-ai-risk) trekken aan de bel: AI kan het einde betekenen van de mensheid. Experts geven dit gemiddeld zelfs [30% kans](https://forum.effectivealtruism.org/posts/8CM9vZ2nnQsWJNsHx/existential-risk-from-ai-survey-results). AI bedrijven racen vooruit en gokken met al onze levens, terwijl regulering hopeloos achterblijft." - Joep Meindertsma, directeur van softwarebedrijf Ontola en oprichter van PauseAI.

De zorgen over de risico's die kleven aan AI zijn mondiaal snel aan het groeien. Deze week nog publiceerde onderzoeksbureau Axios de resultaten van een opiniepeiling onder inwoners van de Verenigde Staten, waaruit [bleek](https://www.axios.com/2023/08/09/ai-voters-trust-government-regulation) dat 86% zich zorgen maakt over catastrofale risico's van AI.

"De VS heeft senaatshoorzittingen waarbij AI experts vertellen over hoe AI het einde kan vormen van de mensheid. Waarom wordt dit onderwerp genegeerd in de Nederlandse politiek? En dat terwijl Nederland een sleutelrol speelt in de chip supply chain, dankzij ASML. Hierom kan het √≥√≥k een sleutelrol spelen in AI compute governance. Alle levens staan op het spel!" - Joep Meindertsma

PauseAI wil dat de Nederlandse regering:

- AI safety-experts uitnodigt om het parlement te informeren over deze risico's
- Een parlementair debat inroostert over de existenti√´le risico's van geavanceerde kunstmatige intelligentie
- Voorbereidingen op de voorgestelde AI-top in het Verenigd Koninkrijk van later dit jaar voorrang geeft en een leidende rol neemt inzake effectief beleid. De actievoerders hebben concrete [voorstellen](https://pauseai.info/summit) en [beleidsidee√´n](https://pauseai.info/proposal) voor de te houden AI-top.
- Internationaal samenwerkt om een toereikende set maatregelen op mondiale schaal toegepast te krijgen, waaronder een zogenoemde AI-pauze.

Voor meer info, bezoek [PauseAI.info](http://pauseai.info). Contact: Joep Meindertsma ([twitter](https://twitter.com/joepmeindertsma), [email](mailto:joep@ontola.io)) & Ruben Dieleman ([email](mailto:ruben@existentialriskobservatory.org))
